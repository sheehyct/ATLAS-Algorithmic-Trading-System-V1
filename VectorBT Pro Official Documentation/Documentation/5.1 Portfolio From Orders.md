---
title: From orders
description: Documentation on simulating portfolios based on orders in VectorBT PRO
icon: material/checkerboard
---

# :material-checkerboard: From orders

Instead of building a custom simulator from scratch, you can use one of the preset simulation methods
provided by VBT. There are three main methods:
[Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders),
[Portfolio.from_signals](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_signals),
and [Portfolio.from_order_func](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_order_func).
Each method has its own advantages and disadvantages, but all follow the same iteration scheme discussed
earlier: they iterate over the rows and columns, and at each step, convert the current element of all
user-provided input data into an order request. They then process the request by updating the current
simulation state and appending the filled order record to an array. This array, along with other
information, can later be used during the reconstruction phase to analyze the simulation.

[Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)
is the simplest of the three methods: it does not accept any UDFs and allows you to provide every detail
about orders as separate, broadcastable arrays. Every element across all provided arrays is converted into
an instance of [Order](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.Order) and processed as usual.
Since the number of orders is limited by the number of elements in the arrays, you can issue and execute
only one order per timestamp and asset.

For example, passing `[0.1, -0.1, np.nan]` as the order size array and `[11, 10, 12]` as the order price
array will generate three orders at three consecutive timestamps:

1. Buy 0.1 shares for $11.
2. Sell 0.1 shares for $10.
3. Do nothing (a size of NaN is ignored).

!!! hint
    This method should be used when you know exactly what to order at each timestamp.
    In practice, many types of signals and other inputs can be successfully converted
    to an order format for a significant speedup. For example, if your entries and exits are
    cleaned (meaning one exit comes exactly after one entry and vice versa), you can convert
    them to order size using `entries.astype(int) - exits.astype(int)`. This will order 1 share
    whenever a signal is encountered, in either direction.

## Numba

The core of this method is the Numba-compiled function
[from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb),
which is the fastest of the three simulation functions. It is also the only one that can be (and is)
safely cached in Numba, since it does not depend on any complex or global data. It uses flexible indexing,
is registered as a chunkable function, and can be parallelized by Numba with a single command.

This simulation function's arguments include some that we have already discussed in the documentation
on simulation: target shape, group lengths, initial cash, and others. Some of the new arguments here include
the call sequence array, initial state arrays (such as `init_position`), continuous state change arrays
(such as `cash_deposits`), order information arrays (such as `size`), and various flags for controlling the
simulation process (such as `save_returns`). Most arguments also have carefully chosen default values that
are consistent across most Numba-compiled functions defined in [portfolio.nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/).

### Order fields

Each field in the named tuple [Order](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.Order)
is available as an argument in this simulation function's signature and can be provided in a format
suitable for flexible indexing.

Let's simulate the three orders mentioned above:

```pycon
>>> from vectorbtpro import *

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(3, 1),  # (1)!
...     group_lens=np.array([1]),  # (2)!
...     size=np.array([[0.1], [-0.1], [np.nan]]),  # (3)!
...     price=np.array([[11], [10], [12]])
... )
>>> sim_out.order_records
array([(0, 0, 0, 0.1, 11., 0., 0), (1, 0, 1, 0.1, 10., 0., 1)],
      dtype={'names':['id','col','idx','size','price','fees','side'], ...})
```

1. Target shape must be two-dimensional. Values such as `3` and `(3,)` are not valid.
2. A one-dimensional group lengths array is required. Without column grouping, this is just an array of
ones (one group per column).
3. For now, set the size and price arrays to have the same shape as `target_shape`.

The simulation returns an instance of the named tuple
[SimulationOutput](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.SimulationOutput), which contains
the filled order and log records, along with other supporting information for post-analysis:

```pycon
>>> print(vbt.prettify(sim_out))
SimulationOutput(
    order_records=<numpy.ndarray object at 0x7f88606d5710 of shape (2,)>,
    log_records=<numpy.ndarray object at 0x7f8860907fa8 of shape (0,)>,
    cash_deposits=<numpy.ndarray object at 0x7f8860907f50 of shape (1, 1)>,
    cash_earnings=<numpy.ndarray object at 0x7f8860a355b0 of shape (1, 1)>,
    call_seq=None,
    in_outputs=FSInOutputs(
        returns=<numpy.ndarray object at 0x7f88a1976fa8 of shape (0, 0)>
    )
)
```

!!! info
    Even though we did not instruct VBT to create arrays for log records, cash deposits,
    or cash earnings, these arrays still appear in the simulation output. Because Numba has
    difficulty processing optional writable arrays, these outputs cannot be set to `None`.
    Instead, VBT creates empty arrays with ultra-small shapes to indicate that they should
    be ignored during post-analysis.

Here is a basic helper function to pretty-print order records:

```pycon
>>> def print_orders(target_shape, order_records):
...     wrapper = vbt.ArrayWrapper.from_shape(target_shape)
...     print(vbt.Orders(wrapper, order_records).readable)

>>> print_orders((3, 1), sim_out.order_records)
   Order Id  Column  Timestamp  Size  Price  Fees  Side
0         0       0          0   0.1   11.0   0.0   Buy
1         1       0          1   0.1   10.0   0.0  Sell
```

To apply information to __every__ element, you can provide a scalar. This works because most
simulation methods automatically convert any scalar into a two-dimensional array suitable for
[flexible indexing](https://vectorbt.pro/pvt_6d1b3986/documentation/portfolio/#flexible-indexing). You can also specify
information per row, such as price, using a one-dimensional array, like this:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(3, 1),
...     group_lens=np.array([1]),
...     size=np.array([0.1, -0.1, np.nan]),
...     price=np.array([11, 10, 12]),
...     fees=0.01
... )
>>> print_orders((3, 1), sim_out.order_records)
   Order Id  Column  Timestamp  Size  Price   Fees  Side
0         0       0          0   0.1   11.0  0.011   Buy
1         1       0          1   0.1   10.0  0.010  Sell
```

1. Apply 1% commission to all orders.

!!! important
    The broadcasting rules in VBT differ slightly from NumPy's broadcasting rules. In NumPy,
    `(3,)` arrays are treated as specified per column (and broadcast along rows) in the shape `(3, 1)`,
    but VBT assumes that flexible two-dimensional arrays are always time series and are
    specified per row (and broadcast along columns).

To provide information per column, always wrap it in a two-dimensional array. You can also
make this array have only one row to apply information to all rows.
Let's test multiple size values specified per column, while the price is given per row:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(3, 3),  # (1)!
...     group_lens=np.array([1, 1, 1]),  # (2)!
...     size=np.array([[np.inf, np.nan, -np.inf]]),  # (3)!
...     price=np.array([11, 10, 12]),  # (4)!
...     fees=0.01  # (5)!
... )
>>> print_orders((3, 3), sim_out.order_records)
   Order Id  Column  Timestamp    Size  Price      Fees  Side
0         0       0          0  9.0009   11.0  0.990099   Buy
1         0       2          0  9.0009   11.0  0.990099  Sell
```

1. Shape `(n, m)` results from imaginary broadcasting of all the passed arrays.
2. Three groups, one for each column.
3. Arrays with shape `(1, m)` are specified per column. A size of `np.inf` will buy as much as
possible at every timestamp, a size of `np.nan` will be ignored at every timestamp, and a size of `-np.inf`
will short sell as much as possible at every timestamp.
4. Arrays with shape `(n,)` or `(n, 1)` are specified per row.
5. Scalars and arrays with shape `(1,)` or `(1, 1)` are specified for the entire array.

This approach works the same way as if you manually broadcasted all arrays before passing them.

```pycon
>>> size, price, fees = vbt.broadcast_arrays(  # (1)!
...     np.array([[np.inf, np.nan, -np.inf]]),
...     np.array([11, 10, 12]),
...     0.01
... )
>>> size
array([[ inf,  nan, -inf],
       [ inf,  nan, -inf],
       [ inf,  nan, -inf]])

>>> price
array([[11, 11, 11],
       [10, 10, 10],
       [12, 12, 12]])

>>> fees
array([[0.01, 0.01, 0.01],
       [0.01, 0.01, 0.01],
       [0.01, 0.01, 0.01]])

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=size.shape,  # (1)!
...     group_lens=np.full(size.shape[1], 1),
...     size=size,
...     price=price,
...     fees=fees
... )
>>> print_orders(size.shape, sim_out.order_records)
   Order Id  Column  Timestamp    Size  Price      Fees  Side
0         0       0          0  9.0009   11.0  0.990099   Buy
1         0       2          0  9.0009   11.0  0.990099  Sell
```

1. Use [broadcast_arrays](https://vectorbt.pro/pvt_6d1b3986/api/base/reshaping/#vectorbtpro.base.reshaping.broadcast_arrays).
2. You can use the shape of any broadcasted array since they all now share the same size.

Notice that all arrays have the same shape `(3, 3)`, which becomes the target shape.

!!! important
    Do not use `np.broadcast_arrays` here. In NumPy, one-dimensional arrays are assumed
    to be specified per column.

!!! info
    To learn more about the different arguments and their meanings, visit the API documentation
    for [Order](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.Order).

### Grouping

If any element in the array `group_lens` is greater than 1, VBT assumes that the columns are
grouped and enables cash sharing by default. Let's simulate a portfolio with two assets where we try
to order as many shares as possible in both assets:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(1, 2),  # (1)!
...     group_lens=np.array([2]),  # (2)!
...     size=np.array([[np.inf, np.inf]]),  # (3)!
...     price=np.array([[10, 5]])
... )
>>> print_orders((1, 2), sim_out.order_records)
   Order Id  Column  Timestamp  Size  Price  Fees Side
0         0       0          0  10.0   10.0   0.0  Buy
```

1. One row (bar) and two columns (assets).
2. Create a group with cash sharing consisting of two columns.
3. Provide order information per element by making an array the same shape as `target_shape`.

We see that the first asset used all the available cash, leaving the second asset without funds.

### Call sequence

One useful feature of [from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb)
is that you can supply your own call sequence to change the order in which columns are processed within
their groups. Without a call sequence, the default order is _from left to right_.
For example, let's perform two rebalancing steps using the default call sequence: allocate 100% to the
second asset at the first timestamp, then close out the position and allocate 100% to the first asset
at the second timestamp.

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(2, 2),
...     group_lens=np.array([2]),
...     size=np.array([[0, 1], [1, 0]]),
...     size_type=vbt.pf_enums.SizeType.TargetPercent,
...     price=np.array([[10, 5], [11, 4]])
... )
>>> print_orders((2, 2), sim_out.order_records)
   Order Id  Column  Timestamp  Size  Price  Fees  Side
0         0       1          0  20.0    5.0   0.0   Buy
1         1       1          1  20.0    4.0   0.0  Sell
```

We see that only column `1` has been processed. This is because we tried to allocate 100% to
the first asset without first closing out the second asset at the second timestamp.
To control this order, we can pass our own call sequence:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(2, 2),
...     group_lens=np.array([2]),
...     size=np.array([[0, 1], [1, 0]]),
...     size_type=vbt.pf_enums.SizeType.TargetPercent,
...     price=np.array([[10, 5], [11, 4]]),
...     call_seq=np.array([[0, 1], [1, 0]])  # (1)!
... )
>>> print_orders((2, 2), sim_out.order_records)
   Order Id  Column  Timestamp       Size  Price  Fees  Side
0         0       0          1   7.272727   11.0   0.0   Buy
1         0       1          0  20.000000    5.0   0.0   Buy
2         1       1          1  20.000000    4.0   0.0  Sell
```

1. At the first timestamp: process the first asset, then the second. At the second timestamp:
process the second asset first, then the first. Note that a call sequence must provide exactly one
position per timestamp and asset, so its shape must match `target_shape`.

!!! info
    Order records are partitioned by column and always appear in the order they
    were filled within each column. Also, order ids (the first field) are generated per column, not globally.

At the second timestamp, the first asset now has the funds needed to go long.

To avoid manually providing the call sequence, you can leave it as `None` and enable `auto_call_seq`
instead. In this case, VBT will automatically sort the columns by their approximated order value:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(2, 2),
...     group_lens=np.array([2]),
...     size=np.array([[0, 1], [1, 0]]),
...     size_type=vbt.pf_enums.SizeType.TargetPercent,
...     price=np.array([[10, 5], [11, 4]]),
...     auto_call_seq=True  # (1)!
... )
>>> print_orders((2, 2), sim_out.order_records)
   Order Id  Column  Timestamp       Size  Price  Fees  Side
0         0       0          1   7.272727   11.0   0.0   Buy
1         0       1          0  20.000000    5.0   0.0   Buy
2         1       1          1  20.000000    4.0   0.0  Sell
```

1. Here

Sometimes, you may want to view the sequence in which orders were processed, which is not shown
in the order records. For this, you can provide your own call sequence and let VBT modify it in
place, then return it as a field in the [SimulationOutput](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.SimulationOutput)
named tuple. The call sequence array must be pre-filled with indices in strict order from 0 to `n`,
where `n` is the length of the respective group of columns. You can easily build such an array using
the function [build_call_seq](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/call_seq/#vectorbtpro.portfolio.call_seq.build_call_seq),
which takes the target shape, group lengths, and the call sequence type from
[CallSeqType](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.CallSeqType):

```pycon
>>> from vectorbtpro.portfolio.call_seq import build_call_seq

>>> call_seq = build_call_seq(
...     target_shape=(2, 2),
...     group_lens=np.array([2]),
...     call_seq_type=vbt.pf_enums.CallSeqType.Default  # (1)!
... )

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(2, 2),
...     group_lens=np.array([2]),
...     size=np.array([[0, 1], [1, 0]]),
...     size_type=vbt.pf_enums.SizeType.TargetPercent,
...     price=np.array([[10, 5], [11, 4]]),
...     call_seq=call_seq,
...     auto_call_seq=True
... )
>>> sim_out.call_seq
array([[0, 1],
       [1, 0]])
```

1. If you want VBT to sort the call sequence using `auto_call_seq`, it must be of the type `Default`.

The generated and then sorted call sequence exactly matches the one we constructed manually earlier.

!!! hint
    There is usually little reason to provide your own call sequence. Keeping it as `None` (default)
    and enabling the `auto_call_seq` flag will find the best call sequence in the most
    resource-efficient way.

### Filling returns

In addition to returning order records, you can instruct VBT to also fill the return based
on portfolio value at the end of each bar. The resulting series will be available
under the `returns` field of [SimulationOutput.in_outputs](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.SimulationOutput.in_outputs),
and can be used to calculate various metrics, such as the Sharpe ratio. Let's do the following:
fetch the BTC price and calculate the return of a simple buy-and-hold strategy, and see that the
filled returns closely match the returns calculated directly from the price.

```pycon
>>> data = vbt.YFData.pull("BTC-USD", end="2022-01-01")
>>> symbol_wrapper = data.get_symbol_wrapper()

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=symbol_wrapper.shape_2d,  # (1)!
...     group_lens=np.array([1]),
...     open=data.get("Open").values,  # (2)!
...     high=data.get("High").values,
...     low=data.get("Low").values,
...     close=data.get("Close").values,
...     save_returns=True  # (3)!
... )
>>> returns = symbol_wrapper.wrap(sim_out.in_outputs.returns)  # (4)!
>>> returns
Date
2014-09-17 00:00:00+00:00    0.000000
2014-09-18 00:00:00+00:00   -0.071926
2014-09-19 00:00:00+00:00   -0.069843
...                               ...
2021-12-29 00:00:00+00:00   -0.024042
2021-12-30 00:00:00+00:00    0.015791
2021-12-31 00:00:00+00:00   -0.018476
Freq: D, Name: BTC-USD, Length: 2663, dtype: float64

>>> data.get("Close").vbt.to_returns()  # (5)!
Date
2014-09-17 00:00:00+00:00    0.000000
2014-09-18 00:00:00+00:00   -0.071926
2014-09-19 00:00:00+00:00   -0.069843
...                               ...
2021-12-29 00:00:00+00:00   -0.024042
2021-12-30 00:00:00+00:00    0.015791
2021-12-31 00:00:00+00:00   -0.018476
Freq: D, Name: Close, Length: 2663, dtype: float64
```

1. Use the data's shape as the target shape. Be sure that columns represent symbols and the shape is two-dimensional.
2. Pass OHLC data as separate arrays. Including the open, high, and low prices is optional.
3. Instruct VBT to calculate the portfolio value and return at each timestamp.
4. Extract the return series and convert it to a Pandas object.
5. Buy-and-hold produces the same returns as the close price itself.

Returns are calculated from the value of each group, so the number of columns in the returned time series
matches the number of groups in `group_lens`:

```pycon
>>> mult_data = vbt.YFData.pull(  # (1)!
...     ["BTC-USD", "ETH-USD"],
...     end="2022-01-01",
...     missing_index="drop"
... )
>>> mult_symbol_wrapper = mult_data.get_symbol_wrapper()

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=mult_symbol_wrapper.shape_2d,
...     group_lens=np.array([2]),  # (2)!
...     close=mult_data.get("Close").values,
...     size=np.array([[0.5, 0.5]]),  # (3)!
...     size_type=vbt.pf_enums.SizeType.TargetPercent,
...     save_returns=True
... )
>>> returns = mult_symbol_wrapper\
...     .replace(columns=["group"], ndim=1)\
...     .wrap(sim_out.in_outputs.returns)  # (4)!
>>> returns
Date
2017-11-09 00:00:00+00:00    0.000000
2017-11-10 00:00:00+00:00   -0.070482
2017-11-11 00:00:00+00:00    0.006159
...                               ...
2021-12-29 00:00:00+00:00   -0.034684
2021-12-30 00:00:00+00:00    0.019652
2021-12-31 00:00:00+00:00   -0.013406
Freq: D, Name: group, Length: 1514, dtype: float64
```

1. Fetch two columns (assets) of data.
2. Create a single group with two columns.
3. Define an allocation for each column, allowing the array to broadcast smoothly against the target shape.
4. The wrapper holds metadata per column, but the returned array is per group. Therefore, replace the columns
with the single group we created above.

### Initial state

The initial state defines the starting conditions for the entire trading environment.
It mainly consists of three variables: initial cash, initial position, and the average
entry price of the initial position. Each variable is at most one-dimensional and is defined
either per column or per group.

Of these, initial cash is the most important, and can be set as a flexible array
`init_cash` with values per column or per group if cash sharing is enabled. As a rule of thumb,
it should be either a scalar or a one-dimensional array with the same number of elements
as in `group_lens`.

Let's create a group of two columns and allocate 50% to each column, along with two additional groups
with one column and 100% allocation each. This lets us perform two independent backtests:
one with grouping and one without. If you supply the initial cash as a single number ($100 by default),
the first group will split it among two assets, making the starting condition of the grouped
columns different from that of the columns without grouping. This is not ideal if you
want fair statistical experiments.

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(1, 4),
...     group_lens=np.array([2, 1, 1]),
...     init_cash=100,  # (1)!
...     size=np.array([[0.5, 0.5, 1.0, 1.0]]),  # (2)!
...     size_type=vbt.pf_enums.SizeType.TargetPercent,
...     price=np.array([[10, 11, 10, 11]]),
... )
>>> print_orders((1, 4), sim_out.order_records)
   Order Id  Column  Timestamp       Size  Price  Fees Side
0         0       0          0   5.000000   10.0   0.0  Buy
1         0       1          0   4.545455   11.0   0.0  Buy
2         0       2          0  10.000000   10.0   0.0  Buy
3         0       3          0   9.090909   11.0   0.0  Buy
```

1. Set $100 as the starting cash for all three groups.
2. Evenly split the cash among the two columns in the first group. Remember that size and other order
information must be provided per column (asset), not per group.

Let's fix this by providing the first group with twice as much capital:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=(1, 4),
...     group_lens=np.array([2, 1, 1]),
...     init_cash=np.array([200, 100, 100]),  # (1)!
...     size=np.array([[0.5, 0.5, 1.0, 1.0]]),
...     size_type=vbt.pf_enums.SizeType.TargetPercent,
...     price=np.array([[10, 11, 10, 11]]),
... )
>>> print_orders((1, 4), sim_out.order_records)
   Order Id  Column  Timestamp       Size  Price  Fees Side
0         0       0          0  10.000000   10.0   0.0  Buy
1         0       1          0   9.090909   11.0   0.0  Buy
2         0       2          0  10.000000   10.0   0.0  Buy
3         0       3          0   9.090909   11.0   0.0  Buy
```

1. Provide the initial cash as an array with values per group.

Besides initial cash, you can also set the initial position of each asset at the start of simulation.
Let's start the simulation with 1 BTC and 1 ETH, and calculate the returns:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=mult_symbol_wrapper.shape_2d,
...     group_lens=np.array([1, 1]),
...     init_position=np.array([1, 1]),  # (1)!
...     close=mult_data.get("Close").values,
...     save_returns=True
... )
>>> returns = mult_symbol_wrapper.wrap(sim_out.in_outputs.returns)
>>> returns
symbol                      BTC-USD   ETH-USD
Date                                         
2017-11-09 00:00:00+00:00       NaN       NaN
2017-11-10 00:00:00+00:00 -0.073554 -0.067411
2017-11-11 00:00:00+00:00 -0.039368  0.051555
...                             ...       ...
2021-12-29 00:00:00+00:00 -0.024042 -0.045348
2021-12-30 00:00:00+00:00  0.015791  0.023514
2021-12-31 00:00:00+00:00 -0.018476 -0.008406

[1514 rows x 2 columns]
```

1. Initial position must be provided per column (asset).

The first data point is NaN because VBT cannot calculate the initial value of each portfolio
instance without the entry price for each initial position. To fix this, set the entry
price to the first open price:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=mult_symbol_wrapper.shape_2d,
...     group_lens=np.array([1, 1]),
...     init_position=np.array([1, 1]),
...     init_price=mult_data.get("Open").values[0],  # (1)!
...     close=mult_data.get("Close").values,
...     save_returns=True
... )
>>> returns = mult_symbol_wrapper.wrap(sim_out.in_outputs.returns)
>>> returns
symbol                      BTC-USD   ETH-USD
Date                                         
2017-11-09 00:00:00+00:00 -0.040182  0.029950
2017-11-10 00:00:00+00:00 -0.073554 -0.067411
2017-11-11 00:00:00+00:00 -0.039368  0.051555
...                             ...       ...
2021-12-29 00:00:00+00:00 -0.024042 -0.045348
2021-12-30 00:00:00+00:00  0.015791  0.023514
2021-12-31 00:00:00+00:00 -0.018476 -0.008406

[1514 rows x 2 columns]
```

1. Entry price of the initial position must also be provided per column (asset).

!!! important
    Make sure to distinguish between a column and a group.

    Columns represent individual assets, and most information in VBT must be given at this
    (lowest) level of detail. These arrays must broadcast against `target_shape`. Groups, on
    the other hand, represent collections of assets that share the same cash, and only some variables
    related to cash must be provided per group. Such arrays must broadcast against `group_lens.shape`.

!!! hint
    If you are unsure whether an argument should be a one-dimensional or two-dimensional array,
    check the function's source code. One-dimensional arrays are annotated with
    `FlexArray1dLike`, and two-dimensional arrays with `FlexArray2dLike`. If an argument is required to be
    strictly one-dimensional or two-dimensional (that is, a scalar is not allowed), it is annotated
    with `FlexArray1d` and `FlexArray2d` respectively. If an argument is not flexible at all (meaning
    it must match `target_shape`), it will be just `Array1d` or `Array2d` accordingly.

### Cash deposits

In addition to providing the initial cash, you can also deposit or withdraw arbitrary cash amounts
throughout the simulation. Like `init_cash`, the argument `cash_deposits` must be
specified per group. The difference is that this array can now be specified per row __and__ per column,
allowing you to specify the deposited or withdrawn amount at each timestamp. Thanks to flexible indexing,
you can apply the amount to each element, each row, each group, or the entire frame.
The actual operation takes place at the beginning of each bar.

Let's simulate a simple [DCA](https://www.investopedia.com/terms/d/dollarcostaveraging.asp) strategy
where we deposit $100 at the beginning of each year and invest it right away:

```pycon
>>> cash_deposits = symbol_wrapper.fill(0)  # (1)!
>>> cash_deposits.vbt.set(100, every="Y", inplace=True)

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=symbol_wrapper.shape_2d,
...     group_lens=np.array([1]),
...     cash_deposits=cash_deposits.values,
...     close=data.get("Close").values
... )
>>> print_orders(symbol_wrapper.shape_2d, sim_out.order_records)
   Order Id  Column  Timestamp      Size         Price  Fees Side
0         0       0          0  0.218659    457.334015   0.0  Buy
1         1       0        106  0.318219    314.248993   0.0  Buy
2         2       0        471  0.230238    434.334015   0.0  Buy
3         3       0        837  0.100168    998.325012   0.0  Buy
4         4       0       1202  0.007322  13657.200195   0.0  Buy
5         5       0       1567  0.026018   3843.520020   0.0  Buy
6         6       0       1932  0.013889   7200.174316   0.0  Buy
7         7       0       2298  0.003404  29374.152344   0.0  Buy
```

1. Create an array with the same shape as your data, fill it with zeros,
and set elements at an annual frequency to 100.

Below, we do the same but for a group with two assets and equal allocations. Since the array
`cash_deposits` changes the cash balance, it must have the same number of columns as the number of groups
(with cash sharing).

```pycon
>>> cash_deposits = mult_symbol_wrapper\
...     .replace(columns=["group"], ndim=1)\
...     .fill(0)  # (1)!
>>> cash_deposits.vbt.set(100, every="Y", inplace=True)
>>> size = mult_symbol_wrapper.fill(np.nan)  # (2)!
>>> size.vbt.set(0.5, every="Y", inplace=True)
>>> size.iloc[0] = 0.5  # (3)!

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=mult_symbol_wrapper.shape_2d,
...     group_lens=np.array([2]),
...     cash_deposits=cash_deposits.values,
...     close=mult_data.get("Close").values,
...     size=size.values,
...     size_type=vbt.pf_enums.SizeType.TargetPercent
... )
>>> print_orders(mult_symbol_wrapper.shape_2d, sim_out.order_records)
   Order Id  Column  Timestamp      Size         Price  Fees  Side
0         0       0          0  0.006999   7143.580078   0.0   Buy
1         1       0         53  0.004569  13657.200195   0.0   Buy
2         2       0        418  0.010971   3843.520020   0.0   Buy
3         3       0        783  0.001263   7200.174316   0.0   Buy
4         4       0       1149  0.003404  29374.152344   0.0   Buy
5         0       1          0  0.155820    320.884003   0.0   Buy
6         1       1         53  0.048663    772.640991   0.0   Buy
7         2       1        418  0.410697    140.819412   0.0   Buy
8         3       1        783  0.695013    130.802002   0.0   Buy
9         4       1       1149  0.108007    730.367554   0.0  Sell
```

1. Create an array with one column for our group.
2. Create a size array to allocate 50% of the deposited cash to each asset.
3. Since we have initial cash, allocate at the first timestamp as well.

To withdraw cash, provide a negative amount. If the amount of cash to be withdrawn
exceeds the available cash in your account, only the available cash will be withdrawn.
Let's start with 1 BTC, sell 10% each year, and continuously withdraw the entire cash balance:

```pycon
>>> size = symbol_wrapper.fill(np.nan)  # (1)!
>>> size.vbt.set(-0.1, every="Y", inplace=True)

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=symbol_wrapper.shape_2d,
...     group_lens=np.array([1]),
...     init_position=1,
...     cash_deposits=-np.inf,  # (2)!
...     close=data.get("Close").values,
...     size=size.values,
...     size_type=vbt.pf_enums.SizeType.Percent,  # (3)!
...     direction=vbt.pf_enums.Direction.LongOnly  # (4)!
... )
>>> print_orders(symbol_wrapper.shape_2d, sim_out.order_records)
   Order Id  Column  Timestamp      Size         Price  Fees  Side
0         0       0        106  0.100000    314.248993   0.0  Sell
1         1       0        471  0.090000    434.334015   0.0  Sell
2         2       0        837  0.081000    998.325012   0.0  Sell
3         3       0       1202  0.072900  13657.200195   0.0  Sell
4         4       0       1567  0.065610   3843.520020   0.0  Sell
5         5       0       1932  0.059049   7200.174316   0.0  Sell
6         6       0       2298  0.053144  29374.152344   0.0  Sell

>>> cash_deposits = symbol_wrapper.wrap(sim_out.cash_deposits)  # (5)!
>>> print(cash_deposits[cash_deposits != 0])  # (6)!
Date
2014-09-17 00:00:00+00:00    -100.000000
2015-01-02 00:00:00+00:00     -31.424899
2016-01-02 00:00:00+00:00     -39.090061
2017-01-02 00:00:00+00:00     -80.864326
2018-01-02 00:00:00+00:00    -995.609894
2019-01-02 00:00:00+00:00    -252.173348
2020-01-02 00:00:00+00:00    -425.163093
2021-01-02 00:00:00+00:00   -1561.062890
Name: BTC-USD, dtype: float64
```

1. Create a size array to sell 10% of the current position at an annual frequency.
2. Withdraw as much as possible at each timestamp. Remember that most arrays can be provided
as a scalar to be applied to each element using flexible indexing.
3. The size value indicates the percentage of the current position.
4. Make each order long-only to avoid moving into the short direction.
5. Access and wrap the cash deposits.
6. Positive cash deposits mean cash inflow. Negative cash deposits mean cash outflow.

As you can see, on the first date of each year, we sold 10% of our position. Since any changes
related to cash are applied only at the beginning of each bar, the cash generated from the
transaction can only be withdrawn on the following date. Also, whenever you specify cash deposits,
VBT will create a full-scale array [SimulationOutput.cash_deposits](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.SimulationOutput.cash_deposits)
to record values that could not be met, such as `-np.inf`, which was replaced by the
cash balance at each timestamp. Without this array, we would be unable to properly
reconstruct the simulation during the post-analysis phase.

### Cash earnings

Unlike cash deposits, cash earnings (`cash_earnings`) refer to cash that is either inflowing to
or outflowing from the user and thus has a direct effect on profitability. Cash earnings are also
applied at the end of each bar. For example, you can use (negative) cash earnings to charge a
fixed commission during a set period of time, or to simulate profit-taking from staking
cryptocurrency. One of the most useful applications of cash earnings is for cash dividends, which are
handled with a separate argument, `cash_dividends`. Cash dividends are multiplied by the current position
size and added to cash earnings. Just like with cash deposits, VBT creates a separate array for
cash earnings whenever it finds any non-zero value in either cash earnings or cash dividends provided
by the user, and writes final operations to this array, which is available under
[SimulationOutput.cash_earnings](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.SimulationOutput.cash_earnings).

Let's simulate investing in Apple and keeping the dividends:

```pycon
>>> aapl_data = vbt.YFData.pull("AAPL", end="2022-01-01")
>>> aapl_wrapper = aapl_data.get_symbol_wrapper()
>>> size = aapl_wrapper.fill()  # (1)!
>>> size.iloc[0] = np.inf

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=aapl_wrapper.shape_2d,
...     group_lens=np.array([1]),
...     close=aapl_data.get("Close").values,
...     cash_dividends=aapl_data.get("Dividends").values,
...     size=size.values
... )
>>> print_orders(aapl_wrapper.shape_2d, sim_out.order_records)
   Order Id  Column  Timestamp        Size     Price  Fees Side
0         0       0          0  996.754204  0.100326   0.0  Buy

>>> cash_earnings = aapl_wrapper.wrap(sim_out.cash_earnings)
>>> print(cash_earnings[cash_earnings != 0])  # (2)!
Date
1987-05-11 00:00:00+00:00      0.534260
1987-08-10 00:00:00+00:00      0.534260
1987-11-17 00:00:00+00:00      0.711683
...                                 ...
2021-05-07 00:00:00+00:00    219.285925
2021-08-06 00:00:00+00:00    219.285925
2021-11-05 00:00:00+00:00    219.285925
Name: AAPL, Length: 73, dtype: float64
```

1. Create a size array to buy the maximum amount at the first bar (`np.inf`), then hold (`np.nan`).
2. Positive cash earnings indicate money inflow, negative cash earnings indicate money outflow.

### Max record count

By default, since VBT does not know how many order records will be needed in advance,
it creates an empty array with the same shape as `target_shape` and gradually "appends" new records.
If there are hundreds of thousands or even millions of elements in the target shape,
you may run out of memory trying to create such a large empty array with a complex data type.
To avoid putting too much stress on your RAM, you can specify the maximum number of potential records
for each column using `max_order_records` for order records and `max_log_records` for log records.

For example, if you have tick data with one million data points and want to simulate
a simple strategy where you buy at the first timestamp and sell at the last timestamp,
it makes sense to restrict the number of possible orders in each column to just 2:

```pycon
>>> target_shape = (1000000, 1)
>>> np.random.seed(42)  # (1)!
>>> rand_price = np.random.randint(8, 12, size=target_shape)  # (2)!
>>> size = np.full(target_shape, np.nan)
>>> size[0] = np.inf
>>> size[-1] = -np.inf

>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=target_shape,
...     group_lens=np.array([1]),
...     price=rand_price,
...     size=size,
...     max_order_records=2  # (3)!
... )
>>> print_orders(target_shape, sim_out.order_records)
   Order Id  Column  Timestamp  Size  Price  Fees  Side
0         0       0          0  10.0   10.0   0.0   Buy
1         1       0     999999  20.0    8.0   0.0  Sell
```

1. Set a seed to make the results reproducible.
2. Generate a random time series to use as a price.
3. We expect to create just two orders.

Exceeding this limit will cause an error:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=target_shape,
...     group_lens=np.array([1]),
...     price=rand_price,
...     size=size,
...     max_order_records=1  # (1)!
... )
IndexError: order_records index out of range. Set a higher max_order_records.
```

1. Reduce the maximum number of order records to 1.

You can also completely disable filling order records by setting `max_order_records` to zero:

```pycon
>>> sim_out = vbt.pf_nb.from_orders_nb(
...     target_shape=target_shape,
...     group_lens=np.array([1]),
...     price=rand_price,
...     size=size,
...     max_order_records=0
... )
>>> print_orders(target_shape, sim_out.order_records)
Empty DataFrame
Columns: [Order Id, Column, Timestamp, Size, Price, Fees, Side]
Index: []
```

!!! note
    `max_order_records` and `max_log_records` apply to each column. If one column needs to generate 2 records
    and another needs 1000 records, use the value 1000. Also, do not reduce the maximum
    number of log records (except for setting it to zero) since logs are generated at every timestamp.

### Jitting

Every simulation function, including [from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb),
is registered as a jittable function in the [JITRegistry](https://vectorbt.pro/pvt_6d1b3986/api/registries/jit_registry/#vectorbtpro.registries.jit_registry.JITRegistry)
once VBT is imported. The so-called "jittable setup" resulting from the registration includes various
details about compilation and decoration, such as which arguments were passed to Numba's `@njit` decorator.
At any time, you can instruct the registry to redecorate the function while keeping the other decoration
arguments at their defaults. For example, to disable Numba and run the simulator as a normal Python function:

```pycon
>>> f_py = vbt.jit_reg.resolve_option(
...     task_id=vbt.pf_nb.from_orders_nb, 
...     option=False  # (1)!
... )
```

1. The option is resolved using [resolve_jitted_option](https://vectorbt.pro/pvt_6d1b3986/api/utils/jitting/#vectorbtpro.utils.jitting.resolve_jitted_option).

To disable caching:

```pycon
>>> f_no_cache = vbt.jit_reg.resolve_option(
...     task_id=vbt.pf_nb.from_orders_nb, 
...     option=dict(cache=False)
... )
```

To enable automatic parallelization:

```pycon
>>> f_parallel = vbt.jit_reg.resolve_option(
...     task_id=vbt.pf_nb.from_orders_nb, 
...     option=dict(parallel=True)
... )
```

!!! hint
    All returned functions can be used exactly the same way as `from_orders_nb`.
    The two latter functions can also be called from within Numba.

### Chunking

The same principle applies to chunking: each simulation function is registered as a chunkable function in
the [ChunkableRegistry](https://vectorbt.pro/pvt_6d1b3986/api/registries/ch_registry/#vectorbtpro.registries.ch_registry.ChunkableRegistry),
and all arguments in [from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb)
are perfectly chunkable across __groups__ (not rows or columns!). However, since Numba-compiled functions
are intended to be used by other Numba-compiled functions, and Numba cannot call regular Python functions,
they have not yet been decorated with the [chunked](https://vectorbt.pro/pvt_6d1b3986/api/utils/chunking/#vectorbtpro.utils.chunking.chunked)
decorator. To decorate the function, you need to explicitly tell the registry:

```pycon
>>> f_chunked = vbt.ch_reg.resolve_option(
...     setup_id_or_func=vbt.pf_nb.from_orders_nb, 
...     option=True  # (1)!
... )
>>> print(vbt.prettify(f_chunked.options))
Config(
    n_chunks=None,
    size=ArraySizer(
        arg_query='group_lens',
        single_type=None,
        axis=0
    ),
    min_size=None,
    chunk_len=None,
    chunk_meta=None,
    skip_single_chunk=None,
    arg_take_spec={...},
    template_context=None,
    engine=None,
    engine_config={},
    merge_func=<function merge_sim_outs at 0x7f88873f1ea0>,
    merge_kwargs={...},
    return_raw_chunks=False,
    silence_warnings=None,
    disable=None
)
```

1. The option is resolved using [resolve_chunked_option](https://vectorbt.pro/pvt_6d1b3986/api/utils/chunking/#vectorbtpro.utils.chunking.resolve_chunked_option).

!!! hint
    The returned function can be used just like `from_orders_nb`, but not within Numba,
    since it is now wrapped with a regular Python function for chunking.

Let's go all in on BTC and ETH while using chunking. This approach will produce two fully isolated
simulations. Internally, the process splits `group_lens` into two arrays (`[1]` and `[1]`), then separates
each argument value into chunks so that each chunk contains information only for one group. It then runs
the same function on different chunks with [Dask](https://dask.org/), and finally merges the results
from both simulations as if they were generated by a single, monolithic simulation :magic_wand:

```pycon
>>> sim_out = f_chunked(
...     target_shape=mult_symbol_wrapper.shape_2d,
...     group_lens=np.array([1, 1]),
...     close=mult_data.get("Close").values,
...     _n_chunks=2,  # (1)!
...     _execute_kwargs=dict(engine="dask")
... )
>>> print_orders(mult_symbol_wrapper.shape_2d, sim_out.order_records)
   Order Id  Column  Timestamp      Size        Price  Fees Side
0         0       0          0  0.013999  7143.580078   0.0  Buy
1         0       1          0  0.311639   320.884003   0.0  Buy
```

1. Add an underscore before an argument to override a setting with the same name in
[chunked](https://vectorbt.pro/pvt_6d1b3986/api/utils/chunking/#vectorbtpro.utils.chunking.chunked).

Chunking can even split flexible arrays!

## Class method

Often, using the Numba-compiled simulation function directly can be cumbersome because many inputs are
scalars or Pandas objects that need to be converted to NumPy arrays. However, understanding how inputs
are handled at the most fundamental level is essential for learning how VBT works behind the
scenes. To make this process easier, VBT wraps each simulation function with a class method, such
as [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)
for [from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb).
This wrapper automates some input pre-processing and output post-processing.

For example, here is how simple it is to test the three orders mentioned at the beginning:

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=[11, 10, 12],
...     size=[0.1, -0.1, np.nan]
... )
>>> pf.orders.readable
   Order Id  Column  Timestamp  Size  Price  Fees  Side
0         0       0          0   0.1   11.0   0.0   Buy
1         1       0          1   0.1   10.0   0.0  Sell
```

But the simplest example is just a single order (for $10, buy 1 share):

```pycon
>>> pf = vbt.Portfolio.from_orders(10, 1)  # (1)!
>>> pf.orders.readable
   Order Id  Column  Timestamp  Size  Price  Fees Side
0         0       0          0   1.0   10.0   0.0  Buy
```

1. Any array-like argument will be converted into a NumPy array.

Each class method acts as a small pipeline that retrieves default argument values from global settings,
broadcasts arguments, checks argument data types, redecorates the simulation function for jitting and
chunking, runs the simulation, and finally creates a new
[Portfolio](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio)
instance based on the simulation result. This instance is ready for analysis.
Most importantly, it leverages Pandas, including datetime indexes and column hierarchies—because nobody
wants to work with only NumPy arrays!

### Close price

Unlike their Numba-compiled counterparts, the class methods require you to provide the close price.
This requirement is tied to the post-analysis stage: many metrics and time series, such as the equity
curve, can only be reliably calculated using the latest price at each bar. These metrics rely on
information available during the bar, and we want to avoid referencing future data, such as the open
price or other intermediate points.

### Defaults

If you examine the signature of [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders),
you will notice many arguments have a default value of `None`. The value `None` has a specific
meaning and typically instructs VBT to replace it with the appropriate default from the global 
settings.

```pycon
>>> vbt.phelp(vbt.Portfolio.from_orders, incl_doc=False)
Portfolio.from_orders(
    close,
    size=None,
    size_type=None,
    direction=None,
    price=None,
    fees=None,
    ...
    jitted=None,
    chunked=None,
    wrapper_kwargs=None,
    freq=None,
    bm_close=None,
    **kwargs
)
```

The global settings for [Portfolio](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio) are found in
the config [settings.portfolio](https://vectorbt.pro/pvt_6d1b3986/api/_settings/#vectorbtpro._settings.portfolio). For example,
by default, VBT uses the close price as the order price (remember that negative infinity means
the open price and positive infinity means the close price?):

```pycon
>>> vbt.settings.portfolio["price"]
inf
```

To change a default, you can override it directly in the settings. For example, let's introduce a
fixed commission of $1 to every order:

```pycon
>>> vbt.settings.portfolio["fixed_fees"] = 1

>>> pf = vbt.Portfolio.from_orders(
...     close=pd.Series([11, 10, 12]),
...     size=pd.Series([0.1, -0.1, np.nan])
... )
>>> pf.orders.readable
   Order Id  Column  Timestamp  Size  Price  Fees  Side
0         0       0          0   0.1   11.0   1.0   Buy
1         1       0          1   0.1   10.0   1.0  Sell
                                               ^
                                              here
```

Settings can be reset just like any other [config](https://vectorbt.pro/pvt_6d1b3986/api/utils/config/#vectorbtpro.utils.config.Config):

```pycon
>>> vbt.settings.portfolio.reset()

>>> vbt.settings.portfolio["fixed_fees"]
0.0
```

In general, global defaults follow the same pattern as the keyword arguments across most simulation
functions. For example, `price` defaults to `np.array(np.inf)` almost everywhere in Numba. If you
cannot find an argument in the global settings, it means there is no default for that argument,
and `None` is a valid value.

### Enums

Within the VBT ecosystem, many arguments are of an enumerated type. Enums are regular integers that
act as categorical variables. Like contexts, they are also represented by named tuples, but these tuples
are already initialized with values, usually ranging from 0 to the total number of categories in the enum.
As an example, consider [SizeType](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.SizeType):

```pycon
>>> print(vbt.prettify(vbt.pf_enums.SizeType))
SizeTypeT(
    Amount=0,
    Value=1,
    Percent=2,
    TargetAmount=3,
    TargetValue=4,
    TargetPercent=5
)
```

Instead of requiring users to provide each value as an integer, you can pass the name of the field and
convert it to an integer using [map_enum_fields](https://vectorbt.pro/pvt_6d1b3986/api/utils/enum_/#vectorbtpro.utils.enum_.map_enum_fields).
This function takes the field name and the enumerated type and returns the corresponding value.
Additionally, it lets you convert entire collections of fields, such as lists or Pandas objects.

```pycon
>>> vbt.map_enum_fields("targetamount", vbt.pf_enums.SizeType)
3

>>> vbt.map_enum_fields([
...     "amount",
...     "targetamount",
...     "targetpercent"
... ], vbt.pf_enums.SizeType)
[0, 3, 5]
```

Internally, this function uses [apply_mapping](https://vectorbt.pro/pvt_6d1b3986/api/utils/mapping/#vectorbtpro.utils.mapping.apply_mapping),
which provides options like ignoring the input if it is already an integer:

```pycon
>>> vbt.map_enum_fields(3, vbt.pf_enums.SizeType)
3
```

By default, it also ignores case and removes all non-alphanumeric characters:

```pycon
>>> vbt.map_enum_fields("Target Amount", vbt.pf_enums.SizeType)
3
```

That's the magic behind [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)
and other simulation methods knowing how to handle string options! For example, let's enter a position of
one share at one bar and then sell 50 percent of it at the next bar:

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=pd.Series([10, 11]),
...     size=pd.Series([1, -0.5]),
...     size_type=pd.Series(["amount", "percent"]),
...     direction="longonly"
... )
>>> pf.orders.readable
   Order Id  Column  Timestamp  Size  Price  Fees  Side
0         0       0          0   1.0   10.0   0.0   Buy
1         1       0          1   0.5   11.0   0.0  Sell
```

!!! note
    Conversion is not vectorized. For large arrays, it is best to use integers directly to avoid
    performance penalties.

### Broadcasting

Once argument values are resolved, VBT identifies all arguments that should broadcast against the
target shape and passes them to the function [broadcast](https://vectorbt.pro/pvt_6d1b3986/api/base/reshaping/#vectorbtpro.base.reshaping.broadcast).

Broadcasting is one of the most important features in VBT because it allows you to provide arrays
with various shapes and types, including NumPy arrays, Pandas Series and DataFrames, and even regular
lists. Whenever we iterate over rows (timestamps) and columns (assets), the simulator needs to know
which element to pick from each array. Instead of providing large arrays with every element set,
you can pass some arrays with elements per row, some per column, and some as scalars, and the
broadcaster will ensure they align perfectly with the target shape over which the simulator iterates.

Let's manually broadcast some arrays. In this example, we have one column in the price array and want
to test multiple combinations of order size by making `size` a DataFrame with one row and multiple columns:

```pycon
>>> close = pd.Series(
...     [11, 10, 12], 
...     index=vbt.date_range("2020-01-01", periods=3)
... )
>>> size = pd.DataFrame(
...     [[-np.inf, np.nan, np.inf]],
...     columns=pd.Index(["short", "nan", "long"], name="size")
... )
>>> fees = 0.01

>>> broadcasted = vbt.broadcast(dict(
...     close=close,
...     size=size,
...     fees=0.01
... ))
>>> broadcasted["close"]
size        short  nan  long
2020-01-01     11   11    11
2020-01-02     10   10    10
2020-01-03     12   12    12

>>> broadcasted["size"]
size        short  nan  long
2020-01-01   -inf  NaN   inf
2020-01-02   -inf  NaN   inf
2020-01-03   -inf  NaN   inf

>>> broadcasted["fees"]
size        short   nan  long
2020-01-01   0.01  0.01  0.01
2020-01-02   0.01  0.01  0.01
2020-01-03   0.01  0.01  0.01
```

Thanks to flexible indexing, you do not have to expand each argument to the full shape or materialize it.
To avoid high memory usage, each simulation method passes `keep_flex=True` to the broadcaster, keeping
all arguments in their original form for flexible indexing. For these arguments, the broadcaster
only checks whether they __can broadcast__ to the desired shape. Since you can broadcast not only
NumPy arrays but also Pandas objects, the broadcaster returns the wrapper resulting from the broadcasting
operation, which contains the final shape and Pandas metadata, including the index and columns:

```pycon
>>> broadcasted, wrapper = vbt.broadcast(dict(
...     close=close,
...     size=size,
...     fees=0.01
... ), keep_flex=True, return_wrapper=True)
>>> broadcasted["close"]
[[11]
 [10]
 [12]]

>>> broadcasted["size"]
[[-inf  nan  inf]]

>>> broadcasted["fees"]
[0.01]

>>> wrapper.fill()  # (1)!
size        short  nan  long
2020-01-01    NaN  NaN   NaN
2020-01-02    NaN  NaN   NaN
2020-01-03    NaN  NaN   NaN
```

1. Create a dummy array to reveal the broadcasted Pandas metadata.

!!! hint
    Even though we passed `fees` as a scalar, the broadcaster automatically wrapped it in a NumPy 
    array and expanded it to two dimensions for Numba. For the same reason, it also converted Pandas to NumPy.

Some arrays, such as `init_cash` and `cash_deposits`, cannot be broadcasted together with `close`
because their final shape depends on the number of groups or because they are inherently one-dimensional.
Therefore, after all regular arrays have been aligned, the wrapper has been created, and the target shape
has been established, VBT will first create the group lengths array, and then individually broadcast
all arrays that cannot be broadcasted against `target_shape`. For example, to broadcast
the initial position array:

```pycon
>>> init_position = 1
>>> new_init_position = vbt.broadcast_array_to(init_position, wrapper.shape_2d[1])
>>> new_init_position
array([1, 1, 1])
```

All of this is handled automatically by [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)!

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=close,
...     size=size,
...     fees=fees,
...     init_position=init_position
... )
>>> pf.orders.readable
   Order Id Column  Timestamp       Size  Price      Fees  Side
0         0  short 2020-01-01  10.981098   11.0  1.207921  Sell
1         0   long 2020-01-01   9.000900   11.0  0.990099   Buy

>>> pf.value
size             short    nan        long
2020-01-01  109.792079  111.0  110.009901
2020-01-02  119.773177  110.0  100.009001
2020-01-03   99.810981  112.0  120.010801
```

To control the broadcasting process, you can pass additional arguments to
[broadcast](https://vectorbt.pro/pvt_6d1b3986/api/base/reshaping/#vectorbtpro.base.reshaping.broadcast) using `broadcast_kwargs`.
For example, let's set custom final columns:

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=close,
...     size=size,
...     fees=fees,
...     init_position=init_position,
...     broadcast_kwargs=dict(columns_from=["a", "b", "c"])
... )
>>> pf.value
                     a      b           c
2020-01-01  109.792079  111.0  110.009901
2020-01-02  119.773177  110.0  100.009001
2020-01-03   99.810981  112.0  120.010801
```

You can also wrap any argument with the class [BCO](https://vectorbt.pro/pvt_6d1b3986/api/base/reshaping/#vectorbtpro.base.reshaping.BCO)
to provide broadcasting-related keyword arguments specifically for that object, or with the class
[Param](https://vectorbt.pro/pvt_6d1b3986/api/utils/params/#vectorbtpro.utils.params.Param) to mark the object as a parameter.
Below, we are testing the Cartesian product of two parameters: size and fees.

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=close,
...     size=vbt.Param([-np.inf, np.inf]),  # (1)!
...     fees=vbt.Param([0, 0.01]),
...     init_position=init_position
... )
>>> pf.value
size                          -inf                     inf            
fees              0.00        0.01        0.00        0.01
2020-01-01  111.000000  109.792079  111.000000  110.009901
2020-01-02  121.090909  119.773177  100.909091  100.009001
2020-01-03  100.909091   99.810981  121.090909  120.010801
```

1. You could also pass a regular `pd.Index` for the same effect.

Furthermore, you can broadcast differently shaped Pandas DataFrames if their column levels overlap.
Suppose you have two assets and want to test using both the open and close price as the order price.
For this, create a Pandas DataFrame for the order price with four columns, one for each price type
per asset:

```pycon
>>> mult_close = mult_data.get("Close")
>>> mult_close
symbol                          BTC-USD      ETH-USD
Date                                                
2017-11-09 00:00:00+00:00   7143.580078   320.884003
2017-11-10 00:00:00+00:00   6618.140137   299.252991
2017-11-11 00:00:00+00:00   6357.600098   314.681000
...                                 ...          ...
2021-12-29 00:00:00+00:00  46444.710938  3628.531738
2021-12-30 00:00:00+00:00  47178.125000  3713.852051
2021-12-31 00:00:00+00:00  46306.445312  3682.632812

[1514 rows x 2 columns]

>>> mult_price = pd.concat((
...     mult_data.get("Open"),
...     mult_data.get("Close")
... ), axis=1, keys=pd.Index(["open", "close"], name="price"))
>>> mult_price
price                              open                      close  \
symbol                          BTC-USD      ETH-USD       BTC-USD   
Date                                                                 
2017-11-09 00:00:00+00:00   7446.830078   308.644989   7143.580078   
2017-11-10 00:00:00+00:00   7173.729980   320.670990   6618.140137   
2017-11-11 00:00:00+00:00   6618.609863   298.585999   6357.600098   
...                                 ...          ...           ...   
2021-12-29 00:00:00+00:00  47623.871094  3797.436279  46444.710938   
2021-12-30 00:00:00+00:00  46490.605469  3632.219727  47178.125000   
2021-12-31 00:00:00+00:00  47169.371094  3713.430176  46306.445312   

price                                   
symbol                         ETH-USD  
Date                                    
2017-11-09 00:00:00+00:00   320.884003  
2017-11-10 00:00:00+00:00   299.252991  
2017-11-11 00:00:00+00:00   314.681000  
...                                ...  
2021-12-29 00:00:00+00:00  3628.531738  
2021-12-30 00:00:00+00:00  3713.852051  
2021-12-31 00:00:00+00:00  3682.632812  

[1514 rows x 4 columns]
```

Even though both shapes (1524, 2) and (1524, 4) are [not broadcastable](https://numpy.org/doc/stable/user/basics.broadcasting.html)
(!) in NumPy, VBT recognizes that both DataFrames share the same column level `symbol` and aligns
them based on that level using [align_pd_arrays](https://vectorbt.pro/pvt_6d1b3986/api/base/reshaping/#vectorbtpro.base.reshaping.align_pd_arrays),
which results in a successful simulation:

```pycon
>>> pf = vbt.Portfolio.from_orders(close=mult_close, price=mult_price)
>>> pf.value
price                            open                    close             
symbol                        BTC-USD      ETH-USD     BTC-USD      ETH-USD
Date                                                                       
2017-11-09 00:00:00+00:00   95.927798   103.965402  100.000000   100.000000
2017-11-10 00:00:00+00:00   88.871910    96.957022   92.644585    93.258931
2017-11-11 00:00:00+00:00   85.373240   101.955648   88.997394    98.066902
...                               ...          ...         ...          ...
2021-12-29 00:00:00+00:00  623.684312  1175.632804  650.160150  1130.792345
2021-12-30 00:00:00+00:00  633.532987  1203.276315  660.426908  1157.381490
2021-12-31 00:00:00+00:00  621.827608  1193.161381  648.224627  1147.652355

[1514 rows x 4 columns]
```

!!! info
    See the API documentation for [broadcast](https://vectorbt.pro/pvt_6d1b3986/api/base/reshaping/#vectorbtpro.base.reshaping.broadcast)
    for more examples on broadcasting.

Even though [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)
is the most basic simulation method, it already accepts dozens of broadcastable array-like arguments.
So, how do you know exactly which argument is broadcastable?

To determine which arguments can be broadcasted, check the API documentation for the argument,
or look at the annotation of the argument in the source code. If its type is `ArrayLike`, it can be
provided both as a scalar and as an array. You can also examine the argument annotations of the
Numba-compiled simulation function (in this case,
[from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb))
and look for the `FlexArray` prefix. Finally, the last and probably most underrated method
is to check the argument-taking specification of the chunking decorator: arguments that are chunked
using [FlexArraySlicer](https://vectorbt.pro/pvt_6d1b3986/api/base/chunking/#vectorbtpro.base.chunking.FlexArraySlicer) or have `flex`
in the specification name are broadcastable by nature. The specification also reveals the shape
against which the argument should broadcast.

```pycon
>>> print(vbt.prettify(f_chunked.options["arg_take_spec"]["close"]))
FlexArraySlicer(
    single_type=None,
    ignore_none=True,
    mapper={
        'should_cache': True,
        'chunk_meta_cache': {...},
        'arg_query': {
            'pattern': '(group_lens|group_map)',
            'flags': 0
        }
    },
    axis=1
)
```

Here, the argument `close` is expected as a flexible array that is chunked along the column axis
using the group lengths mapper. Since the simulation function is always chunked by its groups,
and this argument's columns are mapped to those groups, it should be specified per column
in `target_shape` instead of per group in `group_lens`. Arguments that have no mapper, such as
`cash_deposits`, are always specified per group:

```pycon
>>> print(vbt.prettify(f_chunked.options["arg_take_spec"]["cash_deposits"]))
FlexArraySlicer(
    single_type=None,
    ignore_none=True,
    mapper=None,
    axis=1
)
```

!!! hint
    As a rule of thumb: if you examine the source code of
    [from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb),
    only the arguments with `portfolio_ch.flex_array_gl_slicer` as their specification 
    are broadcasted together and build the target shape. All other flexible arguments broadcast 
    individually once the target shape has been established.

### Grouping

Since the target shape is now generated from broadcasting instead of being passed manually by the user,
the user cannot provide the group lengths directly. Instead, VBT uses a grouping instruction to
create this array for you. Grouping is performed by constructing a
[Grouper](https://vectorbt.pro/pvt_6d1b3986/api/base/grouping/base/#vectorbtpro.base.grouping.base.Grouper) instance, which
takes the broadcasted columns and a group-by object (`group_by`). It then uses the group-by object
to assign the columns to groups and generate the group lengths array. See the API documentation
for [Grouper](https://vectorbt.pro/pvt_6d1b3986/api/base/grouping/base/#vectorbtpro.base.grouping.base.Grouper) to learn about the different
group-by options. For example, you can pass `group_by=True` to put all columns into a single group,
or specify the column level by which the columns should be grouped.

And although [from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb)
automatically enables cash sharing whenever it detects multiple columns in a group, you must explicitly 
enable cash sharing with `cash_sharing` in the class method, or grouping will not be performed 
during the simulation! This is because a [Portfolio](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio)
instance can also group its columns during the post-analysis phase, and `cash_sharing`
is a special flag that tells VBT to group during the simulation as well.

Let's demonstrate how investing all the initial cash into two assets behaves with no grouping, with grouping,
and with grouping plus cash sharing:

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=mult_data.get("Close")
... )
>>> pf.value  # (1)!
symbol                        BTC-USD      ETH-USD
Date                                              
2017-11-09 00:00:00+00:00  100.000000   100.000000
2017-11-10 00:00:00+00:00   92.644585    93.258931
2017-11-11 00:00:00+00:00   88.997394    98.066902
...                               ...          ...
2021-12-29 00:00:00+00:00  650.160150  1130.792345
2021-12-30 00:00:00+00:00  660.426908  1157.381490
2021-12-31 00:00:00+00:00  648.224627  1147.652355

[1514 rows x 2 columns]

>>> pf = vbt.Portfolio.from_orders(
...     close=mult_data.get("Close"),
...     group_by=True
... )
>>> pf.value  # (2)!
Date
2017-11-09 00:00:00+00:00     200.000000
2017-11-10 00:00:00+00:00     185.903516
2017-11-11 00:00:00+00:00     187.064296
...                                  ...
2021-12-29 00:00:00+00:00    1780.952495
2021-12-30 00:00:00+00:00    1817.808397
2021-12-31 00:00:00+00:00    1795.876982
Freq: D, Name: group, Length: 1514, dtype: float64

>>> pf = vbt.Portfolio.from_orders(
...     close=mult_data.get("Close"),
...     group_by=True,
...     cash_sharing=True
... )
>>> pf.value  # (3)!
Date
2017-11-09 00:00:00+00:00    100.000000
2017-11-10 00:00:00+00:00     92.644585
2017-11-11 00:00:00+00:00     88.997394
...                                 ...
2021-12-29 00:00:00+00:00    650.160150
2021-12-30 00:00:00+00:00    660.426908
2021-12-31 00:00:00+00:00    648.224627
Freq: D, Name: group, Length: 1514, dtype: float64
```

1. Without grouping, each column manages its own initial cash.
2. With grouping but without cash sharing, each column still manages its own initial cash.
However, during the post-analysis phase, VBT concatenates both columns to analyze them as a single group,
so the first value appears as $200 instead of $100.
3. With grouping and cash sharing, both columns share the same initial cash. The first column 
invested the entire amount, leaving the second column with insufficient funds, so the value effectively 
reflects only the first asset.

Passing `group_by=True` is only suitable when all columns represent different assets and there are no parameter
combinations. So, what happens when there are multiple assets and parameter combinations?

Let's experiment with different group-by instructions on the `mult_close` and `mult_price` arrays 
we created earlier. The resulting broadcasted shape has 4 columns: each price type for each asset.
Our goal is to create two groups, each containing the assets for one parameter combination.
We cannot use `group_by=True` because it would combine all 4 columns. We also cannot
group by the column level `symbol`, as this would group by asset and place all columns with `BTC-USD` (such as `(Open, BTC-USD)` and `(Close, BTC-USD)`) together, and all `ETH-USD` columns together.
Instead, we need to group `(Open, BTC-USD)` and `(Open, ETH-USD)` together, and `(Close, BTC-USD)` 
and `(Close, ETH-USD)` together; meaning, we need to use all column levels __except for symbols__ as `group_by`.
This can be done in multiple ways:

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=mult_close, 
...     price=mult_price,
...     group_by=pd.Index(["group1", "group1", "group2", "group2"])  # (1)!
... )
>>> pf.value
                                group1       group2
Date                                               
2017-11-09 00:00:00+00:00   199.893199   200.000000
2017-11-10 00:00:00+00:00   185.828932   185.903516
2017-11-11 00:00:00+00:00   187.328888   187.064296
...                                ...          ...
2021-12-29 00:00:00+00:00  1799.317116  1780.952495
2021-12-30 00:00:00+00:00  1836.809302  1817.808397
2021-12-31 00:00:00+00:00  1814.988988  1795.876982

[1514 rows x 2 columns]

>>> pf = vbt.Portfolio.from_orders(
...     close=mult_close, 
...     price=mult_price,
...     group_by=["price"]  # (2)!
... )
>>> pf.value
price                             open        close
Date                                               
2017-11-09 00:00:00+00:00   199.893199   200.000000
2017-11-10 00:00:00+00:00   185.828932   185.903516
2017-11-11 00:00:00+00:00   187.328888   187.064296
...                                ...          ...
2021-12-29 00:00:00+00:00  1799.317116  1780.952495
2021-12-30 00:00:00+00:00  1836.809302  1817.808397
2021-12-31 00:00:00+00:00  1814.988988  1795.876982

[1514 rows x 2 columns]

>>> pf = vbt.Portfolio.from_orders(
...     close=mult_close, 
...     price=mult_price,
...     group_by=vbt.ExceptLevel("symbol")  # (3)!
... )
>>> pf.value
price                             open        close
Date                                               
2017-11-09 00:00:00+00:00   199.893199   200.000000
2017-11-10 00:00:00+00:00   185.828932   185.903516
2017-11-11 00:00:00+00:00   187.328888   187.064296
...                                ...          ...
2021-12-29 00:00:00+00:00  1799.317116  1780.952495
2021-12-30 00:00:00+00:00  1836.809302  1817.808397
2021-12-31 00:00:00+00:00  1814.988988  1795.876982
```

1. Manually pass any collection of group labels, ideally a Pandas Index. This collection
will be converted into a column level. It must have the same length as the number of columns 
in the target shape.
2. Pass the names of all column levels except for the one with the assets. This works only 
when there are multiple levels, meaning the column index is a `pd.MultiIndex`. The grouped column levels 
will be shown in the final column hierarchy.
3. Pass the asset-level column to [ExceptLevel](https://vectorbt.pro/pvt_6d1b3986/api/base/indexes/#vectorbtpro.base.indexes.ExceptLevel)
to group all column levels except that one. This approach works with any column index and 
is the most flexible option.

!!! important
    To ensure the grouping operation on assets worked as expected, the final column
    hierarchy should include all column levels except the one for asset symbols. For example,
    passing `group_by=True` will hide all column levels, while passing `group_by='symbol'`
    will display only the asset symbol column level :x:

### Call sequence

Similar to grouping, the class method makes handling call sequences easier. There is an
argument `call_seq` that not only accepts a (broadcastable) array, but can also take
a value from the enum [CallSeqType](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.CallSeqType).
For example, you can set it to "auto" to automatically sort the call sequence so assets that should be 
sold are executed before assets that should be bought. This is an important requirement for 
rebalancing. Let's create an equally-weighted portfolio that is rebalanced each month:

```pycon
>>> size = mult_symbol_wrapper.fill(np.nan)
>>> size.vbt.set(0.5, every="M", inplace=True)
>>> size.iloc[0] = 0.5

>>> pf = vbt.Portfolio.from_orders(
...     close=mult_data.get("Close"), 
...     size=size,
...     size_type="targetpercent",
...     group_by=vbt.ExceptLevel("symbol"),
...     cash_sharing=True,
...     call_seq="auto"
... )
>>> allocations = pf.get_asset_value(group_by=False).vbt / pf.value
>>> allocations.vbt.plot(  # (1)!
...    trace_kwargs=dict(stackgroup="one"),
...    use_gl=False
... ).show()
```

1. Plot how much each asset contributes to the portfolio value.

![](https://vectorbt.pro/pvt_6d1b3986/assets/images/documentation/pf/from_orders_call_seq.light.svg#only-light){: .iimg loading=lazy }
![](https://vectorbt.pro/pvt_6d1b3986/assets/images/documentation/pf/from_orders_call_seq.dark.svg#only-dark){: .iimg loading=lazy }

!!! hint
    By the way, this is exactly how 
    [Portfolio.from_optimizer](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_optimizer)
    uses [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders) 
    for rebalancing!

To access the sorted call sequence after the simulation, you can pass `attach_call_seq` and
then use the property [Portfolio.call_seq](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.call_seq):

```pycon
>>> pf = vbt.Portfolio.from_orders(
...     close=mult_data.get("Close"), 
...     size=size,
...     size_type="targetpercent",
...     group_by=vbt.ExceptLevel("symbol"),
...     cash_sharing=True,
...     call_seq="auto",
...     attach_call_seq=True  # (1)!
... )
>>> pf.call_seq
symbol                     BTC-USD  ETH-USD
Date                                       
2017-11-09 00:00:00+00:00        0        1
2017-11-10 00:00:00+00:00        1        0
2017-11-11 00:00:00+00:00        1        0
...                            ...      ...
2021-12-29 00:00:00+00:00        1        0
2021-12-30 00:00:00+00:00        1        0
2021-12-31 00:00:00+00:00        1        0

[1514 rows x 2 columns]
```

1. Access the stored call sequence after the simulation.

### Unlimited cash

When backtesting many trading strategies and parameter combinations, cash can quickly become a limiting factor. 
Choosing the right amount of starting capital can also be a challenge on its own. Fortunately, there are 
several options that let's backtest a trading strategy without worrying about cash constraints. One common 
approach is to pass `np.inf` as `init_cash` to simulate an unlimited cash balance. Welcome to the billionaires 
club :money_with_wings:

However, this approach would cause issues during post-analysis because the portfolio value at each timestamp 
would be infinite. To address this, we can tell VBT to simulate unlimited cash during the backtest, 
and then analyze the actual expenditures afterward to determine the optimal starting capital needed. 
If desired, we can then rerun the simulation with the calculated amount. To facilitate this, we can pass
an option from [InitCashMode](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.InitCashMode)
as `init_cash`. Unlike other enums, this one contains only negative values, so it cannot be confused 
with zero or positive amounts.

!!! important
    During the simulation, each group value will be infinity. Therefore, we cannot use sizes of (+/-) 
    infinity, or use percentages, target percentages, or any size types that depend on the group value.
    Returns also cannot be calculated during the simulation.

Let's [DCA](https://www.investopedia.com/terms/d/dollarcostaveraging.asp) into BTC and ETH by buying one unit 
each year. Afterward, we can see how much capital would have been required for this activity:

```pycon
>>> size = mult_symbol_wrapper.fill(np.nan)
>>> size.vbt.set(1, every="Y", inplace=True)
>>> size.iloc[0] = 1

>>> pf = vbt.Portfolio.from_orders(
...     close=mult_data.get("Close"), 
...     size=size,
...     init_cash="auto"  # (1)!
... )
>>> pf.init_cash  # (2)!
symbol
BTC-USD    61218.626953
ETH-USD     2095.513962
Name: init_cash, dtype: float64
```

1. Use [InitCashMode.Auto](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.InitCashMode.Auto).
2. Calculated after the simulation.

We can then use these amounts in a new simulation if desired:

```pycon
>>> pf2 = vbt.Portfolio.from_orders(
...     close=mult_data.get("Close"), 
...     size=size,
...     init_cash=pf.init_cash
... )
>>> pf2.cash.loc[~size.isnull().all(axis=1)]  # (1)!
symbol                          BTC-USD      ETH-USD
Date                                                
2017-11-09 00:00:00+00:00  54075.046875  1774.629959
2018-01-01 00:00:00+00:00  40417.846680  1001.988968
2019-01-01 00:00:00+00:00  36574.326660   861.169556
2020-01-01 00:00:00+00:00  29374.152344   730.367554
2021-01-01 00:00:00+00:00      0.000000     0.000000
```

1. Display the cash balance after each investment.

We can observe how each investment reduces the cash balance, and how the final investment depletes
it completely, while still allowing us to purchase exactly one unit of each cryptocurrency:

```pycon
>>> pf2.orders.readable
   Order Id   Column                 Timestamp  Size         Price  Fees Side
0         0  BTC-USD 2017-11-09 00:00:00+00:00   1.0   7143.580078   0.0  Buy
1         1  BTC-USD 2018-01-01 00:00:00+00:00   1.0  13657.200195   0.0  Buy
2         2  BTC-USD 2019-01-01 00:00:00+00:00   1.0   3843.520020   0.0  Buy
3         3  BTC-USD 2020-01-01 00:00:00+00:00   1.0   7200.174316   0.0  Buy
4         4  BTC-USD 2021-01-01 00:00:00+00:00   1.0  29374.152344   0.0  Buy
5         0  ETH-USD 2017-11-09 00:00:00+00:00   1.0    320.884003   0.0  Buy
6         1  ETH-USD 2018-01-01 00:00:00+00:00   1.0    772.640991   0.0  Buy
7         2  ETH-USD 2019-01-01 00:00:00+00:00   1.0    140.819412   0.0  Buy
8         3  ETH-USD 2020-01-01 00:00:00+00:00   1.0    130.802002   0.0  Buy
9         4  ETH-USD 2021-01-01 00:00:00+00:00   1.0    730.367554   0.0  Buy
```

### Output arrays

All arrays returned as part of [SimulationOutput](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.SimulationOutput),
such as `cash_deposits`, `cash_earnings`, and `in_outputs.returns`, can be accessed as attributes 
with the same name on a [Portfolio](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio) instance.
Let's repeat the same example as in [Cash deposits](#cash-deposits):

```pycon
>>> size = symbol_wrapper.fill(np.nan)
>>> size.vbt.set(-0.1, every="Y", inplace=True)

>>> pf = vbt.Portfolio.from_orders(
...     close=data.get("Close"),
...     size=size,
...     size_type="percent",
...     direction="longonly",
...     init_position=1,
...     cash_deposits=-np.inf
... )
>>> pf.cash_deposits[pf.cash_deposits != 0]
Date
2014-09-17 00:00:00+00:00    -100.000000
2015-01-02 00:00:00+00:00     -31.424899
2016-01-02 00:00:00+00:00     -39.090061
2017-01-02 00:00:00+00:00     -80.864326
2018-01-02 00:00:00+00:00    -995.609894
2019-01-02 00:00:00+00:00    -252.173348
2020-01-02 00:00:00+00:00    -425.163093
2021-01-02 00:00:00+00:00   -1561.062890
dtype: float64
```

### Max record count

Another automation provided by [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)
is managing the maximum number of order and log records. Whenever we pass `None`, 
[from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb)
will choose the maximum possible number of records. In the class method, VBT
counts the number of non-NaN values in the size array and selects the highest count
across all columns. The same process applies to logs, where it checks the number of `True` values.
This automation has almost no impact on performance because VBT does not need to fully broadcast
both arrays to get these numbers. Therefore, we do not need to provide `max_order_records` or `max_log_records`
if we choose to represent inactive data points with NaN in a large close array.

### Data type checks

Numba brings static typing to VBT, and passing incorrect
data types to Numba usually results in a poorly formatted exception. To make debugging easier,
VBT validates all data types before calling 
[from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb).

```pycon
>>> vbt.Portfolio.from_orders(True)
AssertionError: Data type of 'close' must be <class 'numpy.number'>, not bool
```

In this case, the argument `close` must be a numeric data type :relieved:

!!! note
    In VBT, almost no function will change an array's data type silently,
    since casting can be expensive in terms of performance, especially for large arrays.
    It is each user's responsibility to supply properly typed and sized data!

### Jitting

Recall how we handled various jitting options to redecorate 
[from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb)?
Just as elsewhere in VBT, you can pass a jitting option to the class method using the 
argument `jitted`. Let's run a random simulation both without and with automatic Numba parallelization:

```pycon
>>> big_target_shape = (1000, 1000)
>>> big_rand_price = np.random.randint(8, 12, size=big_target_shape)
>>> big_size = np.full(big_target_shape, 1)
>>> big_size[1::2] = -1
```

```pycon
>>> %%timeit
>>> vbt.Portfolio.from_orders(
...     close=big_rand_price, 
...     size=big_size
... )
113 ms ± 2.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
```

```pycon
>>> %%timeit
>>> vbt.Portfolio.from_orders(
...     close=big_rand_price, 
...     size=big_size,
...     jitted=dict(parallel=True)
... )
97 ms ± 3.47 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
```

!!! info
    Preset simulators like [from_orders_nb](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/nb/from_orders/#vectorbtpro.portfolio.nb.from_orders.from_orders_nb)
    can only be parallelized along groups and columns. Therefore, enabling parallel mode will not
    help when there is only one group or one column present. Also, it is often better to use
    chunking instead, because Numba parallelization may provide little or no performance benefit.
    Only custom user pipelines with heavy math can be well parallelized with Numba.

### Chunking

Just like jitting, chunking can be enabled by passing an option to the `chunked` argument. 
Below, we repeat the above benchmark using Dask:

```pycon
>>> %%timeit
>>> vbt.Portfolio.from_orders(
...     close=big_rand_price, 
...     size=big_size,
...     chunked=dict(engine="dask", n_chunks=4)
... )
67.2 ms ± 3.63 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
```

!!! info
    Multithreading with Dask is often better suited than multiprocessing with Ray,
    because by default, all Numba-compiled functions in VBT release the [GIL](https://realpython.com/python-gil/).
    There is much less overhead when starting multiple threads compared to processes.
    Consider using multiprocessing only when the function takes a significant amount of time to run.

### Use cases

This method is ideal for backtesting when order information is known in advance,
and no order changes its parameters in response to changing market conditions.
That means we cannot use it to implement SL, TP, limit, or any other advanced order types.
It is simply a smart way to represent multiple instances of 
[Order](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.Order) in a highly vectorized and efficient way.
Imagine how difficult it would be to provide a list of named tuples instead of arrays! There
are two main use cases where [Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)
really shines: portfolio rebalancing with predefined weights, and "what-if" analysis.
We have already discussed rebalancing in detail. The "what-if" use case is 
about simulating and analyzing various hypothetical scenarios of real-world trading activity.

For example, suppose you made 3 trades on SOL/BTC on Binance and want to analyze them deeply.
Even though Binance now has improved trade analysis features, doing it with VBT
opens up a completely new dimension. First, you need to obtain the close price at the desired granularity 
for analysis. Then, you need to convert the trade information into orders.
Finally, you can use [Portfolio](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio) to explore 
how your portfolio evolved over time!

```pycon
>>> trade1 = dict(
...     timestamp="2022-01-22 12:39:26",
...     price=0.0027702,
...     size=4.99,
...     fixed_fees=1.01571e-05  # (1)!
... )
>>> trade2 = dict(
...     timestamp="2022-01-29 02:12:50",
...     price=0.00243,
...     size=-1.72,
...     fixed_fees=3.0549e-06
... )
>>> trade3 = dict(
...     timestamp="2022-01-29 02:52:54",
...     price=0.0024299,
...     size=-3.27,
...     fixed_fees=5.8102e-06
... )

>>> trades = pd.DataFrame([trade1, trade2, trade3])  # (2)!
>>> trades["timestamp"] = pd.to_datetime(trades["timestamp"], utc=True)  # (3)!
>>> trades.set_index("timestamp", inplace=True)
>>> trades
                             price  size  fixed_fees
timestamp                                           
2022-01-22 12:39:26+00:00  0.00277  4.99    0.000010
2022-01-29 02:52:54+00:00  0.00243 -1.72    0.000003
2022-01-29 02:52:54+00:00  0.00243 -3.27    0.000006

>>> solbtc_data = vbt.BinanceData.pull(  # (4)!
...     "SOLBTC", 
...     start=trades.index[0] - pd.Timedelta(days=1), 
...     end=trades.index[-1] + pd.Timedelta(days=1),
...     timeframe="1h"
... )

>>> resampler = vbt.Resampler(  # (5)!
...     source_index=trades.index, 
...     target_index=solbtc_data.wrapper.index,
...     source_freq=None,
...     target_freq="1h"
... )

>>> # (6)!

>>> @njit
... def avg_price_reduce_meta_nb(from_i, to_i, col, size, price):  # (7)!
...     _size = size[from_i:to_i, col]
...     _price = price[from_i:to_i, col]
...     return np.sum(_price * _size) / np.sum(_size)

>>> price = pd.Series.vbt.resample_to_index(  # (8)!
...     resampler, 
...     avg_price_reduce_meta_nb,
...     vbt.to_2d_array(trades["size"]),
...     vbt.to_2d_array(trades["price"]),
...     wrapper=trades["price"].vbt.wrapper,
... )
>>> price.loc[~price.isnull()]  # (9)!
Open time
2022-01-22 12:00:00+00:00    0.00277
2022-01-29 02:00:00+00:00    0.00243
Freq: 158H, Name: price, dtype: float64

>>> size = trades["size"].vbt.resample_to_index(  # (10)!
...     resampler, 
...     vbt.nb.sum_reduce_nb
... )
>>> size.loc[~size.isnull()]
Open time
2022-01-22 12:00:00+00:00    4.99
2022-01-29 02:00:00+00:00   -4.99
Freq: 158H, Name: size, dtype: float64

>>> fixed_fees = trades["fixed_fees"].vbt.resample_to_index(
...     resampler, 
...     vbt.nb.sum_reduce_nb
... )
>>> fixed_fees.loc[~fixed_fees.isnull()]
Open time
2022-01-22 12:00:00+00:00    0.000010
2022-01-29 02:00:00+00:00    0.000009
Freq: 158H, Name: fixed_fees, dtype: float64

>>> pf = vbt.Portfolio.from_orders(  # (11)!
...     open=solbtc_data.get("Open"),
...     high=solbtc_data.get("High"),
...     low=solbtc_data.get("Low"),
...     close=solbtc_data.get("Close"),
...     price=price,
...     size=size,
...     fixed_fees=fixed_fees,
...     init_cash=0.1,
...     ffill_val_price=False,
...     skipna=True
... )
>>> pf.orders.readable  # (12)!
   Order Id  Column                 Timestamp  Size    Price      Fees  Side
0         0       0 2022-01-22 12:00:00+00:00  4.99  0.00277  0.000010   Buy
1         1       0 2022-01-29 02:00:00+00:00  4.99  0.00243  0.000009  Sell

>>> pf.plot().show()  # (13)!
```

1. Commission for each trade is given in absolute terms, so we call it "fixed fees"
to avoid confusion with "fees" that are usually expressed as a percentage. Also, make sure this amount 
is specified in the quote currency (BTC in this example).
2. Store the trades in a DataFrame for easier handling.
3. The timezone must match the one used by Binance, which is UTC.
4. Pull hourly SOL/BTC data starting from the day before the first trade and ending the day after the last trade 
(this time buffer is optional).
5. The datetime index of the pulled data acts as the backbone for our time-series analysis, 
so we need to align our trades with timestamps present in this index. To do this, create an instance of 
[Resampler](https://vectorbt.pro/pvt_6d1b3986/api/base/resampling/base/#vectorbtpro.base.resampling.base.Resampler) to map
trade timestamps to the pulled bar times.
6. Since some trades (such as the second and third in our example) may fall within the same hour and 
[Portfolio.from_orders](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio.from_orders)
cannot execute multiple orders at the same bar, we need to aggregate their information.
7. Implement a meta function to compute the size-weighted average price for all trades that fall within the same bar.
8. Pass the resampler and meta function to [GenericAccessor.resample_to_index](https://vectorbt.pro/pvt_6d1b3986/api/generic/accessors/#vectorbtpro.generic.accessors.GenericAccessor.resample_to_index)
to resample the trade price.
9. Display the aggregated price points for validation.
10. Size and fixed fees can be easily aggregated using the sum operation.
11. Backtest these trades by setting the initial "cash" to 0.1 BTC and skipping missing data points.
12. Filled orders now have the same information as the original trades.
13. Plot the portfolio.

![](https://vectorbt.pro/pvt_6d1b3986/assets/images/documentation/pf/from_orders_pf_plot.light.svg#only-light){: .iimg loading=lazy }
![](https://vectorbt.pro/pvt_6d1b3986/assets/images/documentation/pf/from_orders_pf_plot.dark.svg#only-dark){: .iimg loading=lazy }

Now you can change the `size`, `price`, and `fixed_fees` arrays as you wish and re-run the simulation to 
observe how your trading strategy's performance changes :dna:

## Summary

As we have seen, VBT offers a variety of preset simulators, each built around a Numba-compiled
core, and a class method on top of [Portfolio](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/base/#vectorbtpro.portfolio.base.Portfolio)
that wraps the core and provides enhancements for a more user-friendly experience. Specifically,
we examined the most basic simulator, "from orders," which takes an input shape 
(timestamps x assets + parameter combinations) and, for each single element, combines different pieces of 
information like puzzle pieces to create an order instance. To visualize this: imagine taking all the arrays, 
broadcasting them on the fly to a common shape, and overlaying them to form a cube. Each element, when 
viewed from above, is a vector with order information from [Order](https://vectorbt.pro/pvt_6d1b3986/api/portfolio/enums/#vectorbtpro.portfolio.enums.Order).

Thanks to flexible indexing, there is no need to broadcast and materialize all these arrays.
VBT is smart enough to project (that is, extrapolate) smaller arrays to larger shapes,
allowing you to provide incomplete information per timestamp, per asset, or for the entire matrix,
as if you had supplied the information for each element. This minimizes memory usage,
enabling you to work with large datasets and perform hyperparameter optimization within Numba,
as long as all input arrays fit into RAM, of course :wink:

Lastly, this documentation has given you insight into how VBT builds layers of abstraction
to automate tasks. We started with simple buy and sell commands, added many features along the way,
and arrived at a Python method that makes backtesting almost unbelievably easy.
Still, this method sits at a lower level: it cannot backtest trading strategies where orders depend
on the current simulation state, meaning all order information must be known before starting the simulation.
Get ready, because this is where signals and order functions come into play!

[:material-language-python: Python code](https://vectorbt.pro/pvt_6d1b3986/assets/jupytext/documentation/portfolio/from-orders.py.txt){ .md-button target="blank_" }