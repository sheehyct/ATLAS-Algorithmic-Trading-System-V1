---
title: Scheduling
description: Documentation on scheduling data updates and saves in VectorBT PRO
icon: material/timer-outline
---

# :material-timer-outline: Scheduling

Most data sources are not idle; they continuously generate new data. To stay up-to-date, we can use a 
schedule manager (or even a simple while loop) to periodically run tasks such as data capturing and 
manipulation.

## Updating

We can easily schedule data updates using [DataUpdater](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater).
This class accepts a data instance of type [Data](https://vectorbt.pro/pvt_6d1b3986/api/data/base/#vectorbtpro.data.base.Data) and a
schedule manager of type [ScheduleManager](https://vectorbt.pro/pvt_6d1b3986/api/utils/schedule_/#vectorbtpro.utils.schedule_.ScheduleManager).
It periodically triggers an update that replaces the old data instance with a new one. The new instance 
can be accessed under [DataUpdater.data](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater.data). 
The update occurs in the method [DataUpdater.update](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater.update),
which can be overridden to implement custom logic when new data arrives. Since the updater class is a 
subclass of [Configured](https://vectorbt.pro/pvt_6d1b3986/api/utils/config/#vectorbtpro.utils.config.Configured), it also automatically 
updates its config when `data` changes.

!!! important
    This is one of the few classes in VBT that is not read-only. Do not rely on caching within it!

Let's use this simple yet powerful class to update and plot the last 10 minutes of a Binance ticker
every 10 seconds for 5 minutes. First, pull the latest 10 minutes of data:

```pycon
>>> from vectorbtpro import *

>>> data = vbt.BinanceData.pull(
...     "BTCUSDT", 
...     start="10 minutes ago UTC", 
...     end="now UTC", 
...     timeframe="1m"
... )

>>> data.close
Open time
2022-02-19 20:09:00+00:00    40005.78
2022-02-19 20:10:00+00:00    40001.80
2022-02-19 20:11:00+00:00    40006.45
2022-02-19 20:12:00+00:00    40003.68
2022-02-19 20:13:00+00:00    40022.24
2022-02-19 20:14:00+00:00    40026.73
2022-02-19 20:15:00+00:00    40048.88
2022-02-19 20:16:00+00:00    40044.92
2022-02-19 20:17:00+00:00    40044.03
2022-02-19 20:18:00+00:00    40049.93
Freq: T, Name: Close, dtype: float64
```

Next, subclass [DataUpdater](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater) to accept
the figure and update it along with the data. To make sure nothing is missed visually, after each
update, append the figure's PNG image to a GIF file:

```pycon
>>> import imageio.v2 as imageio

>>> class OHLCFigUpdater(vbt.DataUpdater):
...     _expected_keys = None
...
...     def __init__(self, data, fig, writer=None, display_last=None, 
...                  stop_after=None, **kwargs):
...         vbt.DataUpdater.__init__(  # (1)!
...             self, 
...             data, 
...             writer=writer,  # (2)!
...             display_last=display_last,
...             stop_after=stop_after,
...             **kwargs
...         )
...
...         self._fig = fig
...         self._writer = writer
...         self._display_last = display_last
...         self._stop_after = stop_after
...         self._start_dt = vbt.utc_datetime()  # (3)!
...
...     @property  # (4)!
...     def fig(self):
...         return self._fig
...
...     @property
...     def writer(self):
...         return self._writer
...
...     @property
...     def display_last(self):
...         return self._display_last
...
...     @property
...     def stop_after(self):
...         return self._stop_after
...
...     @property
...     def start_dt(self):
...         return self._start_dt
...         
...     def update(self, **kwargs):
...         vbt.DataUpdater.update(self, **kwargs)  # (5)!
...         
...         df = self.data.get()
...         if self.display_last is not None:
...             df = df[df.index[-1] - self.display_last:]  # (6)!
...
...         trace = self.fig.data[0]
...         with self.fig.batch_update():
...             trace.x = df["Close"].index  # (7)!
...             trace.open = df["Open"].values
...             trace.high = df["High"].values
...             trace.low = df["Low"].values
...             trace.close = df["Close"].values
...
...         if self.writer is not None:
...             fig_data = imageio.imread(self.fig.to_image(format="png"))
...             self.writer.append_data(fig_data)  # (8)!
...
...         if self.stop_after is not None:
...             now_dt = vbt.utc_datetime()
...             if now_dt - self.start_dt >= self.stop_after:
...                 raise vbt.CancelledError  # (9)!
```

1. Call the constructor of `DataUpdater`.
2. Pass all class-specific keyword arguments to include them in the 
[config](https://vectorbt.pro/pvt_6d1b3986/api/utils/config/#vectorbtpro.utils.config.Configured.config).
3. Register the start time.
4. Properties prevent the user (and the program) from overwriting the object, following a convention in VBT.
5. Call `DataUpdater.update`; otherwise, the data will not update.
6. Get the OHLC data within a specific time period (optional).
7. Update the data of the trace (see [Candlestick Charts](https://plotly.com/python/candlestick-charts/)).
8. Append the figure data to the GIF file (optional).
9. Stop once the job has run for a certain amount of time by raising 
[CancelledError](https://vectorbt.pro/pvt_6d1b3986/api/utils/schedule_/#vectorbtpro.utils.schedule_.CancelledError) (optional).

Do not forget to enable logging if needed:

```pycon
>>> import logging

>>> logging.basicConfig(level = logging.INFO)
```

Finally, run the `OHLCFigUpdater` job every 10 seconds:

```pycon
>>> fig = data.plot(ohlc_type="candlestick", plot_volume=False)
>>> fig  # (1)!

>>> with imageio.get_writer("ohlc_fig_updater.gif", duration=250, loop=0) as writer:  # (2)!
...     ohlc_fig_updater = OHLCFigUpdater(
...         data=data, 
...         fig=fig, 
...         writer=writer,
...         display_last=pd.Timedelta(minutes=10),
...         stop_after=pd.Timedelta(minutes=5)
...     )
...     ohlc_fig_updater.update_every(10)  # (3)!
INFO:vectorbtpro.utils.schedule_:Starting schedule manager with jobs [Every 10 seconds do update() (last run: [never], next run: 2022-02-19 21:18:38)]
INFO:vectorbtpro.data.updater:New data has 10 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:18:00+00:00
INFO:vectorbtpro.data.updater:New data has 10 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:18:00+00:00
INFO:vectorbtpro.data.updater:New data has 11 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:19:00+00:00
INFO:vectorbtpro.data.updater:New data has 11 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:19:00+00:00
INFO:vectorbtpro.data.updater:New data has 11 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:19:00+00:00
INFO:vectorbtpro.data.updater:New data has 11 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:19:00+00:00
INFO:vectorbtpro.data.updater:New data has 11 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:19:00+00:00
INFO:vectorbtpro.data.updater:New data has 12 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:20:00+00:00
INFO:vectorbtpro.data.updater:New data has 12 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:20:00+00:00
INFO:vectorbtpro.data.updater:New data has 12 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:20:00+00:00
INFO:vectorbtpro.data.updater:New data has 12 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:20:00+00:00
INFO:vectorbtpro.data.updater:New data has 12 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:20:00+00:00
INFO:vectorbtpro.data.updater:New data has 13 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:21:00+00:00
INFO:vectorbtpro.data.updater:New data has 13 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:21:00+00:00
INFO:vectorbtpro.data.updater:New data has 13 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:21:00+00:00
INFO:vectorbtpro.data.updater:New data has 13 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:21:00+00:00
INFO:vectorbtpro.data.updater:New data has 13 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:21:00+00:00
INFO:vectorbtpro.data.updater:New data has 14 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:22:00+00:00
INFO:vectorbtpro.data.updater:New data has 14 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:22:00+00:00
INFO:vectorbtpro.data.updater:New data has 14 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:22:00+00:00
INFO:vectorbtpro.data.updater:New data has 14 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:22:00+00:00
INFO:vectorbtpro.data.updater:New data has 14 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:22:00+00:00
INFO:vectorbtpro.data.updater:New data has 15 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:23:00+00:00
INFO:vectorbtpro.data.updater:New data has 15 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:23:00+00:00
INFO:vectorbtpro.data.updater:New data has 15 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:23:00+00:00
INFO:vectorbtpro.data.updater:New data has 15 rows from 2022-02-19 20:09:00+00:00 to 2022-02-19 20:23:00+00:00
INFO:vectorbtpro.utils.schedule_:Stopping schedule manager
```

1. Run these two lines in a separate cell to see the updates in real time.
2. Each frame is shown for 250 milliseconds (4 frames per second), and the GIF loops indefinitely.
3. Uses [DataUpdater.update_every](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater.update_every).

To stop the updater early, simply interrupt the execution.

!!! hint
    To run the job in the background, set `in_background` to True. You can then manually stop the
    execution by calling `ohlc_fig_updater.schedule_manager.stop()`.

After the data updater has finished running, you can access all the data:

```pycon
>>> ohlc_fig_updater.data.close
Open time
2022-02-19 20:09:00+00:00    40005.78
2022-02-19 20:10:00+00:00    40001.80
2022-02-19 20:11:00+00:00    40006.45
2022-02-19 20:12:00+00:00    40003.68
2022-02-19 20:13:00+00:00    40022.24
2022-02-19 20:14:00+00:00    40026.73
2022-02-19 20:15:00+00:00    40048.88
2022-02-19 20:16:00+00:00    40044.92
2022-02-19 20:17:00+00:00    40044.03
2022-02-19 20:18:00+00:00    40045.36
2022-02-19 20:19:00+00:00    40047.68
2022-02-19 20:20:00+00:00    40036.74
2022-02-19 20:21:00+00:00    40037.69
2022-02-19 20:22:00+00:00    40039.92
2022-02-19 20:23:00+00:00    40041.62
Freq: T, Name: Close, dtype: float64
```

Here is the generated GIF:

![](https://vectorbt.pro/pvt_6d1b3986/assets/images/documentation/data/ohlc_fig_updater.light.gif#only-light){: .iimg loading=lazy style="width:700px" }
![](https://vectorbt.pro/pvt_6d1b3986/assets/images/documentation/data/ohlc_fig_updater.dark.gif#only-dark){: .iimg loading=lazy style="width:700px" }

!!! hint
    The smallest time unit for [ScheduleManager](https://vectorbt.pro/pvt_6d1b3986/api/utils/schedule_/#vectorbtpro.utils.schedule_.ScheduleManager)
    is one second. For high-precision job scheduling, use a loop with a timer.

## Saving

Regular updates with [DataUpdater](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater) keep all data
in memory at all times. But what if you do not need to access the entire dataset? What if your main
goal is to collect as much data as possible from an exchange and write each update directly to disk in a
tabular format instead of processing it? This approach allows you to create one script to write 
data updates to a file and another script to regularly read that file and perform a job.
Additionally, this method improves data collection resilience to errors because every new batch
of data is saved immediately.

If this workflow fits your needs, the [DataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver) 
class is an excellent choice for such tasks. It subclasses the 
[DataUpdater](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater) class and adds two abstract methods:
[DataSaver.init_save_data](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.init_save_data) and 
[DataSaver.save_data](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.save_data), which handle saving 
the initial data and each new batch of data, respectively, to a file.

The [DataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver) workflow is straightforward.
First, it requires a data instance `data` with some initial data. When you call 
[DataSaver.update_every](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.update_every) with 
`init_save=True`, it saves this data to a file using [DataSaver.init_save_data](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.init_save_data).
Once the initial data is persisted, on each call to [DataSaver.update](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.update),
it fetches the next data update using [Data.update](https://vectorbt.pro/pvt_6d1b3986/api/data/base/#vectorbtpro.data.base.Data.update)
with `concat=False` to avoid storing the entire dataset in memory. It then calls 
[DataSaver.save_data](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.save_data) to **append** the new 
data to the file. This process repeats until the program is stopped by the user or the system.

There are two preset subclasses of [DataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver):

1. [CSVDataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.CSVDataSaver) for writing data updates using 
[Data.to_csv](https://vectorbt.pro/pvt_6d1b3986/api/data/base/#vectorbtpro.data.base.Data.to_csv).
2. [HDFDataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.HDFDataSaver) for writing data updates using 
[Data.to_hdf](https://vectorbt.pro/pvt_6d1b3986/api/data/base/#vectorbtpro.data.base.Data.to_hdf).

Let's pull 1-minute `BTCUSDT` data from Binance and write it to a CSV file every 10 seconds:

```pycon
>>> data = vbt.BinanceData.pull(
...     "BTCUSDT", 
...     start="10 minutes ago UTC", 
...     end="now UTC", 
...     timeframe="1m"
... )

>>> csv_saver = vbt.CSVDataSaver(data)
>>> csv_saver.update_every(10, init_save=True)  # (1)!
INFO:vectorbtpro.data.saver:Saved initial 10 rows from 2022-02-21 23:25:00+00:00 to 2022-02-21 23:34:00+00:00
INFO:vectorbtpro.utils.schedule_:Starting schedule manager with jobs [Every 10 seconds do update() (last run: [never], next run: 2022-02-22 00:34:55)]
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:34:00+00:00 to 2022-02-21 23:34:00+00:00
INFO:vectorbtpro.data.saver:Saved 2 rows from 2022-02-21 23:34:00+00:00 to 2022-02-21 23:35:00+00:00
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:35:00+00:00 to 2022-02-21 23:35:00+00:00
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:35:00+00:00 to 2022-02-21 23:35:00+00:00
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:35:00+00:00 to 2022-02-21 23:35:00+00:00
```

1. Use `init_save` to tell VBT to save the initial data before updating.

!!! important
    If the initial data has not yet been saved to disk, pass `init_save=True` to save it first.
    Otherwise, only the subsequent updates will be saved!

!!! note
    Remember to set up logging as shown in the previous example to view log messages.

Now, let's interrupt the execution and take a look at the data in `csv_saver`:

```pycon
INFO:vectorbtpro.utils.schedule_:Stopping schedule manager

>>> csv_saver.data.close
Open time
2022-02-21 23:35:00+00:00    37185.95
Name: Close, dtype: float64
```

As you can see, unlike the data updater we used previously, the data saver keeps only the latest 
received batch of data in memory, which is needed for the next update. All previously fetched data 
is now stored in a CSV file. Let's take a look:

```pycon
>>> pd.read_csv("BTCUSDT.csv", index_col=0, parse_dates=True)["Close"]  # (1)!
Open time
2022-02-21 23:25:00+00:00    37247.29
2022-02-21 23:26:00+00:00    37296.44
2022-02-21 23:27:00+00:00    37190.16
2022-02-21 23:28:00+00:00    37135.50
2022-02-21 23:29:00+00:00    37186.11
2022-02-21 23:30:00+00:00    37056.19
2022-02-21 23:31:00+00:00    37079.47
2022-02-21 23:32:00+00:00    37181.49
2022-02-21 23:33:00+00:00    37288.48
2022-02-21 23:34:00+00:00    37209.83
2022-02-21 23:34:00+00:00    37240.21
2022-02-21 23:34:00+00:00    37245.64
2022-02-21 23:35:00+00:00    37248.12
2022-02-21 23:35:00+00:00    37213.55
2022-02-21 23:35:00+00:00    37168.76
2022-02-21 23:35:00+00:00    37185.95
Name: Close, dtype: float64
```

1. Use Pandas to view the file without any post-processing.

There are many duplicate index entries. Why is that? Remember, every time we request an update, we
try not only to fetch new data points but also to refresh the most recent ones. If we request
10 updates during a single 1-minute candle, we will get 10 different data points with the same timestamp.
Overwriting any row in a CSV file is very inefficient, as you would need to scan the entire
file just to remove one line. As a result, new data simply gets appended to the file. When we want
to fetch the full dataset, [CSVData](https://vectorbt.pro/pvt_6d1b3986/api/data/custom/csv/#vectorbtpro.data.custom.csv.CSVData) will
automatically remove any duplicates:

```pycon
>>> vbt.CSVData.pull("BTCUSDT.csv").close
Open time
2022-02-21 23:25:00+00:00    37247.29
2022-02-21 23:26:00+00:00    37296.44
2022-02-21 23:27:00+00:00    37190.16
2022-02-21 23:28:00+00:00    37135.50
2022-02-21 23:29:00+00:00    37186.11
2022-02-21 23:30:00+00:00    37056.19
2022-02-21 23:31:00+00:00    37079.47
2022-02-21 23:32:00+00:00    37181.49
2022-02-21 23:33:00+00:00    37288.48
2022-02-21 23:34:00+00:00    37245.64
2022-02-21 23:35:00+00:00    37185.95
Freq: T, Name: Close, dtype: float64
```

To clean the CSV file from duplicates, read the data using 
[CSVData](https://vectorbt.pro/pvt_6d1b3986/api/data/custom/csv/#vectorbtpro.data.custom.csv.CSVData) and write it back:

```pycon
>>> vbt.CSVData.pull("BTCUSDT.csv").to_csv()

>>> pd.read_csv("BTCUSDT.csv", index_col=0, parse_dates=True)["Close"]
Open time
2022-02-21 23:25:00+00:00    37247.29
2022-02-21 23:26:00+00:00    37296.44
2022-02-21 23:27:00+00:00    37190.16
2022-02-21 23:28:00+00:00    37135.50
2022-02-21 23:29:00+00:00    37186.11
2022-02-21 23:30:00+00:00    37056.19
2022-02-21 23:31:00+00:00    37079.47
2022-02-21 23:32:00+00:00    37181.49
2022-02-21 23:33:00+00:00    37288.48
2022-02-21 23:34:00+00:00    37245.64
2022-02-21 23:35:00+00:00    37185.95
Name: Close, dtype: float64
```

!!! info
    The above step is optional and mainly helps save disk space.
    You should perform it only occasionally, mainly when exporting the CSV file to another 
    program for analysis.

You can resume the saving process at any time:

```pycon
>>> csv_saver.update_every(10)  # (1)!
INFO:vectorbtpro.utils.schedule_:Starting schedule manager with jobs [Every 10 seconds do update() (last run: [never], next run: 2022-02-22 00:35:55)]
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:35:00+00:00 to 2022-02-21 23:35:00+00:00
INFO:vectorbtpro.data.saver:Saved 2 rows from 2022-02-21 23:35:00+00:00 to 2022-02-21 23:36:00+00:00
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:36:00+00:00 to 2022-02-21 23:36:00+00:00
INFO:vectorbtpro.utils.schedule_:Stopping schedule manager
```

1. We do not need `init_save` here since this data is already on disk.

!!! note
    If your data provider offers only a limited time window of high-frequency data, avoid pausing
    the saving process for too long, or you may end up with missing data.

If you want to resume the saving process even after restarting your runtime, it is a good idea
to pickle and save the data saver instance to disk:

```pycon
>>> csv_saver.save("csv_saver")  # (1)!
```

1. Using [Pickleable.save](https://vectorbt.pro/pvt_6d1b3986/api/utils/pickling/#vectorbtpro.utils.pickling.Pickleable.save).

You can then continue in a new runtime:

```pycon
>>> import logging
>>> logging.basicConfig(level = logging.INFO)

>>> from vectorbtpro import *
>>> csv_saver = vbt.CSVDataSaver.load("csv_saver")
>>> csv_saver.update_every(10)
INFO:vectorbtpro.utils.schedule_:Starting schedule manager with jobs [Every 10 seconds do update() (last run: [never], next run: 2022-02-22 00:36:45)]
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:36:00+00:00 to 2022-02-21 23:36:00+00:00
INFO:vectorbtpro.data.saver:Saved 1 rows from 2022-02-21 23:36:00+00:00 to 2022-02-21 23:36:00+00:00
INFO:vectorbtpro.data.saver:Saved 2 rows from 2022-02-21 23:36:00+00:00 to 2022-02-21 23:37:00+00:00
INFO:vectorbtpro.utils.schedule_:Stopping schedule manager
```

How can we specify exactly where the data should be stored? [DataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver)
accepts two arguments: `save_kwargs` and `init_save_kwargs`, which are passed to 
[DataSaver.save_data](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.save_data) and 
[DataSaver.init_save_data](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.DataSaver.init_save_data), respectively.
For example, in [CSVDataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.CSVDataSaver), these keyword arguments
are further forwarded to [Data.to_csv](https://vectorbt.pro/pvt_6d1b3986/api/data/base/#vectorbtpro.data.base.Data.to_csv).
To change the directory path, for instance, you can simply do:

```pycon
>>> csv_saver = vbt.CSVDataSaver(
...     save_kwargs=dict(
...         path_or_buf="data",
...         mkdir_kwargs=dict(mkdir=True)
...     )
... )
```

However, this is not the only way to provide keyword arguments for saving. If you look at the arguments
accepted by the method [DataUpdater.update_every](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.updater.DataUpdater.update_every),
you will see `save_kwargs` and `init_save_kwargs` again, which are passed down to their respective methods.
These arguments have higher priority and override any arguments with the same name provided to the constructor.
This approach allows you to customize how the data is saved each time you resume the operation.

The same principle applies to [HDFDataSaver](https://vectorbt.pro/pvt_6d1b3986/api/data/updater/#vectorbtpro.data.saver.HDFDataSaver).

[:material-language-python: Python code](https://vectorbt.pro/pvt_6d1b3986/assets/jupytext/documentation/data/scheduling.py.txt){ .md-button target="blank_" }